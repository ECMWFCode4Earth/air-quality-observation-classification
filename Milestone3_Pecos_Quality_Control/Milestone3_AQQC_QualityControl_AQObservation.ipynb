{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cellular-pricing",
   "metadata": {},
   "source": [
    "# Milestone3_AQQC_QualityControl_AQObservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pecos\n",
    "import seaborn as sns\n",
    "from pandas import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time, timezone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "import re   \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import pecos\n",
    "import seaborn as sns\n",
    "from pandas import json_normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date, time, timezone\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import csv\n",
    "import re   \n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import rgb2hex\n",
    "\n",
    "\n",
    "\n",
    "dashboard_content = {}  # Initialize the dashboard content dictionary\n",
    "\n",
    " \n",
    "def Milestone2_Get_OpenAQ_Dataset_Wrangling_utc_index(OpenAQ_Dataset_ImportAPI):\n",
    "\n",
    "   format = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "   OpenAQ_Dataset_ImportAPI['date.utc'] = pd.to_datetime(OpenAQ_Dataset_ImportAPI['date.utc'], format=format).dt.tz_localize(None)\n",
    "\n",
    "  # OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value != -999.00]\n",
    "\n",
    "   Formating = pd.DatetimeIndex(OpenAQ_Dataset_ImportAPI['date.utc'])\n",
    "  \n",
    "   OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI.set_index(Formating)\n",
    "\n",
    "   return OpenAQ_Dataset_ImportAPI\n",
    "   \n",
    "def Milestone2_Remove_neg_attribute(OpenAQ_Dataset_ImportAPI):\n",
    "    \n",
    "    OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value != -999.00]\n",
    "\n",
    "    return OpenAQ_Dataset_ImportAPI\n",
    "\n",
    "def Milestone2_Remove_negative_attribute(OpenAQ_Dataset_ImportAPI):\n",
    "    \n",
    "    OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value >= 0]\n",
    "\n",
    "    return OpenAQ_Dataset_ImportAPI\n",
    "\n",
    "def Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram_Unique(df4, OpenAQStationunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration):\n",
    "   \n",
    "   OpenAQ_Dataset_Graph_df = [] \n",
    "    \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "      \n",
    "      OpenAQ_Dataset_Graph = []  \n",
    "      \n",
    "      OpenAQ_Dataset_Graph.append(OpenAQunique)\n",
    "      \n",
    "      OpenAQAPIdatasetunique = df4[df4['location'] == OpenAQunique]\n",
    "      \n",
    "      OpenAQStationcompletegetunique = Milestone2_OpenAQStation_remove_NonAlpha(OpenAQunique)\n",
    "            \n",
    "      OpenAQDataset_measureStationVisualAnalytics = OpenAQDataset_VisualAnalytics + \" Station OpenAQ \" + OpenAQStationcompletegetunique\n",
    "      \n",
    "      OpenAQDataset_VisualGraphiteration = OpenAQDataset_VisualAnalytics_iteration + \" Station OpenAQ \" + OpenAQStationcompletegetunique\n",
    "            \n",
    "      OpenAQgraph = Milestone2_OpenAQ_VisualAnalytics_parameters(OpenAQAPIdatasetunique, OpenAQunique, OpenAQDataset_measureStationVisualAnalytics, OpenAQDataset_VisualGraphiteration)\n",
    "      \n",
    "      OpenAQ_Dataset_Graph.append(OpenAQgraph)\n",
    "\n",
    "      OpenAQ_Dataset_Graph_df.append(OpenAQ_Dataset_Graph)\n",
    "\n",
    "   return OpenAQ_Dataset_Graph_df\n",
    "\n",
    "\n",
    "def Milestone2_OpenAQ_VisualAnalytics_parameters(df4,OpenAQselectunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration):\n",
    "        \n",
    "        \n",
    "    OpenAQparameterunique = df4['parameter'].unique()\n",
    "    \n",
    "    OpenAQ_Dataset_uniqueGraph = []  \n",
    "    \n",
    "    \n",
    "    for OpenAQStationparameter in OpenAQparameterunique:\n",
    "        \n",
    "       OpenAQ_Dataset_Graph = []  \n",
    "       \n",
    "       OpenAQ_Dataset_Graph.append(OpenAQselectunique)\n",
    "       \n",
    "      \n",
    "       OpenAQdfunique = df4[df4['parameter'] == OpenAQStationparameter]\n",
    "       \n",
    "       OpenAQDataset_VisualAnalyticsplt = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationparameter\n",
    "       \n",
    "       OpenAQDataset_VisualAnalytic = OpenAQDataset_VisualAnalytics + \" \" + OpenAQStationparameter\n",
    "       \n",
    "       yaxishistogram = \"Amount of Measurements \" + OpenAQStationparameter\n",
    "              \n",
    "       OpenAQ_Dataset_df = Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram(OpenAQdfunique, OpenAQStationparameter, OpenAQDataset_VisualAnalyticsplt, title=OpenAQDataset_VisualAnalytic, xlabel='Value', ylabel=yaxishistogram, dpi=100)\n",
    "      \n",
    "       OpenAQ_Dataset_Graph.append(OpenAQ_Dataset_df)\n",
    "      \n",
    "       yaxis = \"OpenAQ Measurements \" + OpenAQStationparameter\n",
    "       \n",
    "       OpenAQ_Dataset = Milestone2_Import_OpenAQ_CSV_plot(OpenAQdfunique, OpenAQdfunique.index, OpenAQdfunique['value'], OpenAQStationparameter, OpenAQDataset_VisualAnalyticsplt, title=OpenAQDataset_VisualAnalytic, xlabel='Date utc timestamp', ylabel=yaxis, dpi=100)\n",
    "\n",
    "       OpenAQ_Dataset_Graph.append(OpenAQ_Dataset)\n",
    "\n",
    "       OpenAQ_Dataset_Graph.append(OpenAQStationparameter)\n",
    "\n",
    "       OpenAQ_Dataset_uniqueGraph.append(OpenAQ_Dataset_Graph) \n",
    "\n",
    "\n",
    "    OpenAQ_Dataset_uniqueGraph.append(OpenAQparameterunique)\n",
    "\n",
    "    return OpenAQ_Dataset_uniqueGraph\n",
    "\n",
    "def Milestone2_OpenAQStation_remove_NonAlpha(OpenAQStationunique):\n",
    "    \n",
    "   OpenAQStationformatunique = re.sub(r'\\W+', '', str(OpenAQStationunique))\n",
    "  \n",
    "   print(OpenAQStationformatunique)\n",
    "   \n",
    "   return OpenAQStationformatunique\n",
    "\n",
    "def Milestone2_Import_OpenAQ_CSV_plot_Unique(df4, OpenAQStationunique, xaxis, yaxis, parameter, OpenAQDataset_VisualAnalytics, xlabel='Value', ylabel='Amount of Measurements', dpi=100):\n",
    "   \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "        \n",
    "      print(OpenAQunique) \n",
    "       \n",
    "      OpenAQAPIdatasetunique = df4[df4['location'] == OpenAQunique]\n",
    "      \n",
    "      Milestone2_Import_OpenAQ_CSV_plot(OpenAQAPIdataset, xaxis, yaxis, parameter, OpenAQ_Dataset, title=OpenAQDataset_VisualAnalytics, xlabel='Value', ylabel='Amount of Measurements', dpi=100)\n",
    "\n",
    "def Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram(df4, parameter, OpenAQDataset_VisualAnalytics_iteration, title=\"\", xlabel='Value', ylabel='Amount of Measurements', dpi=100):\n",
    "    \n",
    "# Step Create a Histogram of the OpenAQ Dataset for parameter\n",
    "   \n",
    "   print(\"Histogram of OpenAQ Dataset from OpenAQ API download\") \n",
    "    \n",
    "   plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "   \n",
    "   plt.hist(df4['value'], bins=\"auto\")\n",
    "            \n",
    "           # bins=np.arange(1,df4['value'].max()))\n",
    "   \n",
    "   OpenAQ_Dataset =  OpenAQDataset_VisualAnalytics_iteration + \" Histogram\" + \".png\"\n",
    "      \n",
    "   plt.savefig(OpenAQ_Dataset)\n",
    "   \n",
    "   plt.show()\n",
    "\n",
    "   return OpenAQ_Dataset\n",
    "\n",
    "def Milestone2_Import_OpenAQ_CSV_plot(df4, xaxis, yaxis, parameter, OpenAQDataset_VisualAnalytics_iteration,  title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    \n",
    "   print(\"OpenAQ Dataset LinePlot\")\n",
    "     \n",
    "   plt.figure(figsize=(16,5), dpi=dpi)\n",
    "   plt.plot(xaxis, yaxis, color='tab:blue')\n",
    "   plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "       \n",
    "   OpenAQ_Dataset = OpenAQDataset_VisualAnalytics_iteration + \" Line Graph\" + \".png\"\n",
    "        \n",
    "   plt.savefig(OpenAQ_Dataset)\n",
    " \n",
    "   plt.show()\n",
    "\n",
    "   return OpenAQ_Dataset\n",
    "\n",
    "def Milestone1_Get_Parameter(DatasetOpenAQ, Parameter):\n",
    "       \n",
    "   DatasetOpenAQ = DatasetOpenAQ[DatasetOpenAQ.parameter==Parameter]\n",
    "  \n",
    "   return DatasetOpenAQ\n",
    "     \n",
    "def Milestone3_Get_Imported_OpenAQ_Dataset_parameter_unique_Test(OpenAQDatasetparameter, OpenAQ_Dataset_Graph_df, TestId, Test_Analysis):\n",
    "    \n",
    "   OpenAQStationparameter = OpenAQDatasetparameter['parameter'].unique()\n",
    "\n",
    "\n",
    "   for OpenAQStation in OpenAQ_Dataset_Graph_df:\n",
    "       \n",
    "      print(OpenAQStation[1][1])    \n",
    "      \n",
    "      \n",
    "\n",
    "   if(len(OpenAQStationparameter) == 0):\n",
    "     parameter = OpenAQStationparameter[0]\n",
    "  \n",
    "   else:\n",
    "     parameter = Parameter_Default  \n",
    "    \n",
    "   return parameter\n",
    "   \n",
    "def Milestone3_Get_Imported_OpenAQ_Dataset_Test(OpenAQ_Dataset_OpenAQCSV_Download_Test, TestId, Test_Analysis):\n",
    "    \n",
    "   Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQ_Dataset_OpenAQCSV_Download_Test)\n",
    "    \n",
    "def Milestone3_Get_VisualAnalytics(OpenAQDataset, OpenAQStation):\n",
    "     \n",
    "    OpenAQdfDataset = []\n",
    "    \n",
    "    for OpenAQdatasetGraph in OpenAQDataset:\n",
    "      \n",
    "       if(OpenAQdatasetGraph[0] == OpenAQStation): \n",
    "\n",
    "           OpenAQdfDataset = OpenAQdatasetGraph\n",
    "           \n",
    "    return OpenAQdfDataset       \n",
    "           \n",
    "def Milestone3_Pecos_Complete_QC_QualityControl_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQStationunique, OpenAQDataset, yaml_include):\n",
    "    \n",
    "   iteration = 0 \n",
    "    \n",
    "   OpenAQSearchCriteria = \"\"\n",
    "    \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "        \n",
    "      print(OpenAQunique) \n",
    "   \n",
    "      OpenAQSearchCriteria = OpenAQSearchCriteria + \"\"\n",
    "      \n",
    "      OpenAQAPIdatasetunique = OpenAQStation[OpenAQStation['location'] == OpenAQunique]\n",
    "      \n",
    "      OpenAQCompleteDataset = Milestone3_Get_VisualAnalytics(OpenAQDataset, OpenAQunique)\n",
    "      \n",
    "      OpenAQStationcompleteunique = Milestone2_OpenAQStation_remove_NonAlpha(OpenAQunique)\n",
    "      \n",
    "      OpenAQDataset_VisualAnalytics_iteration_unique = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationcompleteunique \n",
    "      \n",
    "      Milestone3_Pecos_Quality_Control_parameters(OpenAQStation[OpenAQStation['location']==OpenAQunique], OpenAQDataset_VisualAnalytics_iteration_unique, OpenAQDataset[iteration][1], OpenAQSearchCriteria, yaml_include, OpenAQunique)\n",
    "\n",
    "      iteration = iteration + 1\n",
    "\n",
    "\n",
    "def Milestone3_Pecos_Quality_Control_parameters(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset, OpenAQSearchCriteria, yaml_include, OpenAQunique):\n",
    "    \n",
    "    OpenAQparameterunique = OpenAQStation['parameter'].unique()\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    for OpenAQStationparameter in OpenAQparameterunique:\n",
    "        \n",
    "       OpenAQSearchCriteria1 = OpenAQSearchCriteria + \"\" + OpenAQStationparameter\n",
    "        \n",
    "       OpenAQDatasetStation = Milestone1_Get_Parameter(OpenAQStation, OpenAQStationparameter)\n",
    "\n",
    "       OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationparameter \n",
    "\n",
    "       if(yaml_include == 1):\n",
    "   \n",
    "           (DA, QCI) = Milestone3_Pecos_Complete_QualityControl_SearchCriteriaOne_OpenAQStation(OpenAQDatasetStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset[iteration], OpenAQSearchCriteria1)\n",
    "           dashboard_cell = generate_dashboard_cell(DA, QCI)\n",
    "           dashboard_content[(OpenAQunique, OpenAQStationparameter)] = dashboard_cell\n",
    "           \n",
    "       else:    \n",
    " \n",
    "           (DA, QCI) = Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation(OpenAQDatasetStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset[iteration]) \n",
    "           dashboard_cell = generate_dashboard_cell(DA, QCI)\n",
    "           dashboard_content[(OpenAQunique, OpenAQStationparameter)] = dashboard_cell\n",
    "          \n",
    "       iteration = iteration + 1        \n",
    "\n",
    "def Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset):\n",
    "\n",
    "   # Step 2 Initialize logger and Create a Pecos PerformanceMonitoring data object\n",
    "   pecos.logger.initialize()\n",
    "   \n",
    "   pm = pecos.monitoring.PerformanceMonitoring()\n",
    "\n",
    "   print()\n",
    "\n",
    "   # Step 3 Append Dataframe to Pecos PerformanceMonitoring data object\n",
    "   pm.add_dataframe(OpenAQStation)\n",
    "\n",
    "   # Step 4 Check the expected frequency of the timestamp\n",
    "   #\n",
    "   # 1 Edit timestep when 900 is 15 mins     \n",
    "\n",
    "   Timestep = 900 # Edit\n",
    "   \n",
    "   pm.check_timestamp(Timestep)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 1 : Timestep \")\n",
    "   \n",
    "   print(Timestep)\n",
    "   \n",
    "   # Step 5 Check for missing data\n",
    "   \n",
    "   \n",
    "   no_missing_values = OpenAQStation.value.isna().sum()\n",
    "   data_availability = (len(OpenAQStation.index) - no_missing_values) / len(OpenAQStation.index)\n",
    "\n",
    "   print(\"data availabilty: \", no_missing_values, data_availability)\n",
    "\n",
    "   \n",
    "   if(QC_CheckDatasetComplete == 1):\n",
    "\n",
    "       pm.check_missing()\n",
    "   \n",
    "# Step 6 Choose acceptable value range and Check data for expected ranges\n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound of values\n",
    "#  2 Higher Bound of values\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Minimum number of consecutive failures for reporting (default = 1)le increment from measurements of 15 minutes and check for abrupt changes between consecutive time steps\n",
    "#\n",
    "#   e.g pm.check_range([0, 200], key='value')  \n",
    "#         pm.check_range([1, 2], key='3',4)\n",
    "#\n",
    "# Results: Any value outside of the range is an outlier\n",
    "\n",
    "   LowerBound = None # Edit \n",
    "   \n",
    "   HigherBound = 400 # Edit\n",
    "\n",
    "   pm.check_range([LowerBound, HigherBound], key='value')\n",
    " \n",
    "   print(\"*****\")\n",
    "   \n",
    "   print(\"Criteria 2 : Lower Bound and Higher Bound \")\n",
    "  \n",
    "   print(\"Lower Bound \")\n",
    "   \n",
    "   print(LowerBound)   \n",
    "   \n",
    "   print(\"Higher Bound\")\n",
    "   \n",
    "   print(HigherBound)\n",
    "   \n",
    "# Step 7 Choose the min amount that is acceptable to change from measurements \n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "#    1 Lower bound to decrease by\n",
    "#    2 Upper bound to increase by\n",
    "#    3 Size of the moving window used to compute the difference between the minimum and maximum\n",
    "#    4 Data column (default = None, which indicates that all columns are used)\n",
    "#    5 Flag indicating if the test should only check for positive delta (the min occurs before the max) or negative delta (the max occurs before the min) (default = False)\n",
    "#    6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "#  e.g. pm.check_delta([Miniumn Decrease, Min Increase], window=3600, 'value')\n",
    "#      included parametes 1-6: pm.check_delta([1, 2], window=3, key='4', 5, 6)\n",
    "#\n",
    "#  Results: When over min decrease or increase it is an outlier\n",
    " \n",
    "   print(\"*****\")\n",
    "  \n",
    "   print(\"Criteria 3 : Stagnant Measurements \")\n",
    "  \n",
    "   DeltaLowerBound = None # Edit\n",
    "   \n",
    "   DeltaHigherBound = 10 # Edit\n",
    "   \n",
    "   DeltaTimeSchedule = 3600 # Edit\n",
    "   \n",
    "   pm.check_delta([DeltaLowerBound, DeltaHigherBound], window=DeltaTimeSchedule, key='value')\n",
    "\n",
    "   print(\" Measurement that increase by \" )\n",
    "   \n",
    "   print(DeltaHigherBound )\n",
    "   \n",
    "   print(\"in Time Schedule\")\n",
    "   \n",
    "   print(DeltaTimeSchedule)\n",
    "\n",
    "   print(\"Delta Lower Bound\")\n",
    "\n",
    "   print(DeltaLowerBound)\n",
    "\n",
    "# Step 8 Choose acceptable increment on measurements \n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound to de increment by\n",
    "#  2 Higher Bound to increment by\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Increment used for difference calculation (default = 1 timestamp)\n",
    "#  5 Flag indicating if the absolute value of the increment is used in the test (default = True)\n",
    "#  6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "# e.g pm.check_increment([None, 20], 'value') \n",
    "#    included parametes 1- 4:  pm.check_increment([1, 2], key='3', 4, 5, 6) \n",
    "#\n",
    "# Results: Any measurement that has a larger increment or de increment by choosen value is an outlier\n",
    "\n",
    "   print(\"*****\")\n",
    " \n",
    "   print(\"Criteria 4 : Maximum Increment of Measurements \")\n",
    "\n",
    "   Increment_Increase = 20 # Edit\n",
    "   \n",
    "   Increment_Decrease = None # Edit\n",
    "  \n",
    "   pm.check_increment([Increment_Decrease, Increment_Increase], key='value') \n",
    "\n",
    "   print(\"Increment Increase\")\n",
    "   \n",
    "   print(Increment_Increase)\n",
    "\n",
    "   print(\"Increment Decrease\")\n",
    "   \n",
    "   print(Increment_Decrease)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 5: Outlier\")\n",
    "   \n",
    "   print(\"UpperBound\")\n",
    "\n",
    "   UpperBoundOutlier = 3 # Edit\n",
    "\n",
    "   LowerBoundOutlier = None # Edit\n",
    "   \n",
    "   print(UpperBoundOutlier)\n",
    "   \n",
    "   print(\"Time Schedule\")\n",
    "     \n",
    "   TimeSchedule = 12*3600 # Edit\n",
    "   \n",
    "   print(TimeSchedule)\n",
    "   \n",
    "   pm.check_outlier([LowerBoundOutlier, UpperBoundOutlier], window=TimeSchedule, key='value')\n",
    "\n",
    "   # Step 9 Compute the quality control index for value\n",
    "   mask = pm.mask[['value']]\n",
    "       \n",
    "   QCI = pecos.metrics.qci(mask)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"OpenAQ Dataset Results \")\n",
    "\n",
    "   print(\"Mask\")\n",
    "  \n",
    "   print(pm.mask) \n",
    "   \n",
    " #  print(pm.cleaned_data[pm.cleaned_data['value'] == 'NaN'])\n",
    "   \n",
    "   print(\"Performance Metrics\")\n",
    "\n",
    "   print(QCI)\n",
    "\n",
    "   custom = 'custom' + OpenAQDataset_VisualAnalytics_iteration + '.png'\n",
    "\n",
    "   custom_graphics_graph = '.png' \n",
    "\n",
    "   MeasurementOpenAQ = int(OpenAQStation['value'].max())\n",
    "\n",
    "   print(OpenAQStation['value'].describe())\n",
    "  \n",
    "    \n",
    "   test_results_graphics_OpenAQ = [] \n",
    "   \n",
    "   # Step 10 Generate graphics\n",
    "   test_results_graphics = pecos.graphics.plot_test_results(pm.df, pm.test_results, filename_root=OpenAQDataset_VisualAnalytics_iteration)\n",
    "   \n",
    "   \n",
    "   \n",
    " #  test_results_graphics_OpenAQ.append(test_results_graphics)\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[1])\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[2])\n",
    "\n",
    "   \n",
    "   OpenAQStation.plot(y='value', ylim=[0,MeasurementOpenAQ], figsize=(7.0,3.5))\n",
    "   plt.savefig(custom, format='png', dpi=500)\n",
    "\n",
    "   print(custom)\n",
    " \n",
    "   test_results_graphics_OpenAQ.append(custom)\n",
    "   \n",
    "   print(pm.test_results)\n",
    " \n",
    " #  OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration \n",
    "\n",
    "   # Step 11 Write test results and report files to test_results.csv and monitoringreport.html\n",
    "\n",
    "   Report = 'test_results' + OpenAQDataset_VisualAnalytics_iteration  + ' Result' + '.csv' \n",
    "\n",
    "   MonitoringReport = 'MonitoringReport' + OpenAQDataset_VisualAnalytics_iteration + '.html'\n",
    "\n",
    "   pecos.io.write_test_results(pm.test_results,filename=Report)\n",
    "   pecos.io.write_monitoring_report(pm.df, pm.test_results, test_results_graphics, \n",
    "                                 test_results_graphics_OpenAQ, QCI,filename=MonitoringReport)\n",
    " \n",
    "   metricsOpenAQ = Milestone3_Get_OpenAQresults(pm.test_results, pm.df, QCI)   \n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(Report)\n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(MonitoringReport)\n",
    "   \n",
    " #  OpenAQDataset_VisualAnalytics_Results.append(OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv')\n",
    "  \n",
    "  # pecos.io.write_metrics(metricsOpenAQ, OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv') \n",
    "\n",
    "   return (data_availability, QCI.value)\n",
    "\n",
    "\n",
    "def Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria):\n",
    "  \n",
    "   if(yaml_Yes == 1):\n",
    "       \n",
    "     import yaml \n",
    "  \n",
    "     config_file = OpenAQSearchCriteria + '_config.yml'\n",
    "     fid = open(config_file, 'r')\n",
    "     config = yaml.load(fid)\n",
    "     fid.close()\n",
    "   else:\n",
    "     \n",
    "     config = PecosQC\n",
    "       \n",
    "   return config  \n",
    "    \n",
    "\n",
    "def Milestone3_Pecos_Complete_QualityControl_SearchCriteriaOne_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset, OpenAQSearchCriteria):\n",
    "\n",
    "   # Step 2 Initialize logger, Get search criteria and Create a Pecos PerformanceMonitoring data object\n",
    "   pecos.logger.initialize()\n",
    "   \n",
    "   PecosQualityControlSearchCriteria = Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria)\n",
    "  \n",
    "   pm = pecos.monitoring.PerformanceMonitoring()\n",
    "\n",
    "   # Step 3 Append Dataframe to Pecos PerformanceMonitoring data object\n",
    "   \n",
    "      \n",
    "   time_increment_mode = get_time_increment_mode(OpenAQStation)\n",
    "\n",
    "   \n",
    "   OpenAQStation = cleanup_dataframe(OpenAQStation, time_increment_mode)\n",
    "\n",
    "   pm.add_dataframe(OpenAQStation)\n",
    "\n",
    "   # Step 4 Check the expected frequency of the timestamp\n",
    "   #\n",
    "   # 1 Edit timestep when 900 is 15 mins     \n",
    "\n",
    "   Timestep = PecosQualityControlSearchCriteria['Criteria1Timestep']['Timestep'] \n",
    "   \n",
    "\n",
    "  \n",
    "   no_missing_values = OpenAQStation.value.isna().sum()\n",
    "   data_availability = (len(OpenAQStation.index) - no_missing_values) / len(OpenAQStation.index)\n",
    "\n",
    "   print(\"data availabilty: \", no_missing_values, data_availability)\n",
    "\n",
    "   \n",
    "\n",
    "   \n",
    "   # Default 900 # Edit\n",
    "   \n",
    "   pm.check_timestamp(Timestep)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 1 : Timestep \")\n",
    "   \n",
    "   print(Timestep)\n",
    "   \n",
    "   # Step 5 Check for missing data\n",
    "   \n",
    "   if(QC_CheckDatasetComplete == 1):\n",
    "\n",
    "       pm.check_missing()\n",
    "   \n",
    "# Step 6 Choose acceptable value range and Check data for expected ranges\n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound of values\n",
    "#  2 Higher Bound of values\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Minimum number of consecutive failures for reporting (default = 1)le increment from measurements of 15 minutes and check for abrupt changes between consecutive time steps\n",
    "#\n",
    "#   e.g pm.check_range([0, 200], key='value')  \n",
    "#         pm.check_range([1, 2], key='3',4)\n",
    "#\n",
    "# Results: Any value outside of the range is an outlier\n",
    "\n",
    "   LowerBound =  PecosQualityControlSearchCriteria['Criteria2LowerHigherBound']['LowerBound']\n",
    "   \n",
    "   # Defualt None # Edit \n",
    "   \n",
    "   HigherBound =  PecosQualityControlSearchCriteria['Criteria2LowerHigherBound']['HigherBound']\n",
    "      \n",
    "   # Default 400 # Edit\n",
    "\n",
    "   pm.check_range([LowerBound, HigherBound], key='value')\n",
    " \n",
    "   print(\"*****\")\n",
    "   \n",
    "   print(\"Criteria 2 : Lower Bound and Higher Bound \")\n",
    "  \n",
    "   print(\"Lower Bound \")\n",
    "   \n",
    "   print(LowerBound)   \n",
    "   \n",
    "   print(\"Higher Bound\")\n",
    "   \n",
    "   print(HigherBound)\n",
    "   \n",
    "# Step 7 Choose the min amount that is acceptable to change from measurements \n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "#    1 Lower bound to decrease by\n",
    "#    2 Upper bound to increase by\n",
    "#    3 Size of the moving window used to compute the difference between the minimum and maximum\n",
    "#    4 Data column (default = None, which indicates that all columns are used)\n",
    "#    5 Flag indicating if the test should only check for positive delta (the min occurs before the max) or negative delta (the max occurs before the min) (default = False)\n",
    "#    6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "#  e.g. pm.check_delta([Miniumn Decrease, Min Increase], window=3600, 'value')\n",
    "#      included parametes 1-6: pm.check_delta([1, 2], window=3, key='4', 5, 6)\n",
    "#\n",
    "#  Results: When over min decrease or increase it is an outlier\n",
    " \n",
    "   print(\"*****\")\n",
    "  \n",
    "   print(\"Criteria 3 : Stagnant Measurements \")\n",
    "  \n",
    "   DeltaLowerBound =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['min']\n",
    "   \n",
    "   \n",
    "   # Default None # Edit\n",
    "   \n",
    "   DeltaHigherBound =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['max']\n",
    "   \n",
    "   # Default 10 # Edit\n",
    "   \n",
    "   DeltaTimeSchedule =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['TimeSchedule']\n",
    "   \n",
    "   # Default 3600 # Edit\n",
    "      \n",
    "   MinbeforeMaxandMaxMin = PecosQualityControlSearchCriteria['Criteria3Stagnant']['MinbeforeMaxandMaxMin']\n",
    "     \n",
    "   MinConsectiveFailures = PecosQualityControlSearchCriteria['Criteria3Stagnant']['MinConsectiveFailures']  \n",
    "   \n",
    "   pm.check_delta([DeltaLowerBound, DeltaHigherBound], window=DeltaTimeSchedule, direction=MinbeforeMaxandMaxMin, min_failures=MinConsectiveFailures, key='value')\n",
    "\n",
    "   print(\" Measurement that increase by \" )\n",
    "   \n",
    "   print(DeltaHigherBound )\n",
    "   \n",
    "   print(\"in Time Schedule\")\n",
    "   \n",
    "   print(DeltaTimeSchedule)\n",
    "\n",
    "   print(\"Delta Lower Bound\")\n",
    "\n",
    "   print(DeltaLowerBound)\n",
    "\n",
    "# Step 8 Choose acceptable increment on measurements \n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound to de increment by\n",
    "#  2 Higher Bound to increment by\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Increment used for difference calculation (default = 1 timestamp)\n",
    "#  5 Flag indicating if the absolute value of the increment is used in the test (default = True)\n",
    "#  6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "# e.g pm.check_increment([None, 20], 'value') \n",
    "#    included parametes 1- 4:  pm.check_increment([1, 2], key='3', 4, 5, 6) \n",
    "#\n",
    "# Results: Any measurement that has a larger increment or de increment by choosen value is an outlier\n",
    "\n",
    "   print(\"*****\")\n",
    " \n",
    "   print(\"Criteria 4 : Maximum Increment of Measurements \")\n",
    "\n",
    "   Increment_Increase = PecosQualityControlSearchCriteria['Criteria4Increment']['max']\n",
    "   \n",
    "   # Default 20 # Edit\n",
    "   \n",
    "   Increment_Decrease = PecosQualityControlSearchCriteria['Criteria4Increment']['min']\n",
    "   \n",
    "   # Default None # Edit\n",
    "  \n",
    "   pm.check_increment([Increment_Decrease, Increment_Increase], key='value') \n",
    "\n",
    "   print(\"Increment Increase\")\n",
    "   \n",
    "   print(Increment_Increase)\n",
    "\n",
    "   print(\"Increment Decrease\")\n",
    "   \n",
    "   print(Increment_Decrease)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 5: Outlier\")\n",
    "   \n",
    "   print(\"UpperBound\")\n",
    "\n",
    "   UpperBoundOutlier = PecosQualityControlSearchCriteria['Criteria5Outlier']['UpperBound']\n",
    "   \n",
    "   \n",
    "   # Default 3 # Edit\n",
    "\n",
    "   LowerBoundOutlier = PecosQualityControlSearchCriteria['Criteria5Outlier']['LowerBound']\n",
    "  \n",
    "   \n",
    "   # None # Edit\n",
    "   \n",
    "   print(UpperBoundOutlier)\n",
    "   \n",
    "   print(\"Time Schedule\")\n",
    "     \n",
    "   TimeSchedule = PecosQualityControlSearchCriteria['Criteria5Outlier']['TimeSchedule']\n",
    "   \n",
    "   # Default 12*3600 # Edit\n",
    "   \n",
    "   print(TimeSchedule)\n",
    "   \n",
    "   pm.check_outlier([LowerBoundOutlier, UpperBoundOutlier], window=TimeSchedule, key='value')\n",
    "\n",
    "   # Step 9 Compute the quality control index for value\n",
    "   mask = pm.mask[['value']]\n",
    "       \n",
    "   QCI = pecos.metrics.qci(mask)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"OpenAQ Dataset Results \")\n",
    "\n",
    "   print(\"Mask\")\n",
    "  \n",
    "   print(pm.mask) \n",
    "   \n",
    " #  print(pm.cleaned_data[pm.cleaned_data['value'] == 'NaN'])\n",
    "   \n",
    "   print(\"Performance Metrics\")\n",
    "\n",
    "   print(QCI)\n",
    "\n",
    "   custom = 'custom' + OpenAQDataset_VisualAnalytics_iteration + '.png'\n",
    "\n",
    "   custom_graphics_graph = '.png' \n",
    "\n",
    "   MeasurementOpenAQ = int(OpenAQStation['value'].max())\n",
    "\n",
    "   print(OpenAQStation['value'].describe())\n",
    "  \n",
    "    \n",
    "   test_results_graphics_OpenAQ = [] \n",
    "   \n",
    "   # Step 10 Generate graphics\n",
    "   test_results_graphics = pecos.graphics.plot_test_results(pm.df, pm.test_results, filename_root=OpenAQDataset_VisualAnalytics_iteration)\n",
    "   \n",
    "   \n",
    "   \n",
    " #  test_results_graphics_OpenAQ.append(test_results_graphics)\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[1])\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[2])\n",
    "\n",
    "   \n",
    "   OpenAQStation.plot(y='value', ylim=[0,MeasurementOpenAQ], figsize=(7.0,3.5))\n",
    "   plt.savefig(custom, format='png', dpi=500)\n",
    "\n",
    "   print(custom)\n",
    " \n",
    "   test_results_graphics_OpenAQ.append(custom)\n",
    "   \n",
    "   print(pm.test_results)\n",
    " \n",
    " #  OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration \n",
    "\n",
    "   # Step 11 Write test results and report files to test_results.csv and monitoringreport.html\n",
    "\n",
    "   Report = 'test_results' + OpenAQDataset_VisualAnalytics_iteration  + ' Result' + '.csv' \n",
    "\n",
    "   MonitoringReport = 'MonitoringReport' + OpenAQDataset_VisualAnalytics_iteration + '.html'\n",
    "\n",
    "   pecos.io.write_test_results(pm.test_results,filename=Report)\n",
    "   pecos.io.write_monitoring_report(pm.df, pm.test_results, test_results_graphics, \n",
    "                                 test_results_graphics_OpenAQ, QCI,filename=MonitoringReport)\n",
    " \n",
    "   metricsOpenAQ = Milestone3_Get_OpenAQresults(pm.test_results, pm.df, QCI)   \n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(Report)\n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(MonitoringReport)\n",
    "   \n",
    " #  OpenAQDataset_VisualAnalytics_Results.append(OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv')\n",
    "  \n",
    "  # pecos.io.write_metrics(metricsOpenAQ, OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv') \n",
    "\n",
    "   return (data_availability, QCI.value)\n",
    "\n",
    "\n",
    "\n",
    "def create_pecos_dashboard(parameter_list, location_list, Dashboard):\n",
    "    footnote = \"DA = Data availability <br>QCI = Quality control index\"\n",
    "\n",
    "    for location in location_list:\n",
    "        for parameter in parameter_list:\n",
    "            if (location, parameter) not in dashboard_content:\n",
    "                dashboard_content[(location, parameter)] = \"&nbsp;\"\n",
    "\n",
    "    pecos.io.write_dashboard(\n",
    "        parameter_list,\n",
    "        location_list,dashboard_content,\n",
    "        footnote=footnote,\n",
    "        filename=Dashboard,\n",
    "    )\n",
    "    \n",
    "    OpenAQDataset_VisualAnalytics_Results.append(Dashboard)\n",
    "    \n",
    "\n",
    "\n",
    "def Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria):\n",
    "  \n",
    "   if(yaml_Yes == 1):\n",
    "       \n",
    "     import yaml \n",
    "  \n",
    "     config_file = OpenAQSearchCriteria + \"_default\"  + '_config.yml'\n",
    "     fid = open(config_file, 'r')\n",
    "     config = yaml.load(fid)\n",
    "     fid.close()\n",
    "   else:\n",
    "     \n",
    "     config = PecosQC\n",
    "       \n",
    "   return config  \n",
    "    \n",
    "\n",
    "def color_value(val):\n",
    "\n",
    "    nThresholds = 10\n",
    "    colors = [(0.75, 0.15, 0.15), (1, 0.75, 0.15), (0.15, 0.75, 0.15)]\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        name=\"custom\", colors=colors, N=nThresholds\n",
    "    )\n",
    "\n",
    "    # print(\"color val\", val)\n",
    "    return_color = \"\"\n",
    "    if np.isnan(val):\n",
    "        return_color = \"background-color: gray\"\n",
    "    elif val > 1:\n",
    "        return_color = \"background-color: gray\"\n",
    "    elif val < 0:\n",
    "        return_color = \"background-color: gray\"\n",
    "    else:\n",
    "        binned_value = int(np.floor(val * 10))\n",
    "        rgb_color = cmap(binned_value)[:3]\n",
    "        hex_color = rgb2hex(rgb_color)\n",
    "        return_color = \"background-color: \" + hex_color\n",
    "\n",
    "    return return_color\n",
    "\n",
    "\n",
    "def cleanup_dataframe(df, time_increment_mode):\n",
    "    \"\"\"replace OpenAQ missing value with np.nan and insert nans where ther are gaps\"\"\"\n",
    "    start_index = df.index[0]\n",
    "    end_index = df.index[-1]\n",
    "    idx = pd.date_range(\n",
    "        start_index, end_index, freq=\"{}S\".format(int(time_increment_mode))\n",
    "    )\n",
    "\n",
    "    df = df.reindex(idx, fill_value=np.nan)\n",
    "    # df.value.replace(-999, np.nan)\n",
    "    # df.value[df.value < 0] = np.nan\n",
    "    df.value = np.where(df.value < 0, np.nan, df.value)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_time_increment_mode(df):\n",
    "\n",
    "    time_diff = (df.index[1:] - df.index[:-1]).values\n",
    "    mode = stats.mode(time_diff).mode[0]\n",
    "    time_increment_mode = mode / np.timedelta64(1, \"s\")\n",
    "    return time_increment_mode\n",
    "\n",
    "def generate_dashboard_cell(DA, QCI):\n",
    "\n",
    "    metrics = pd.DataFrame(data=np.array([DA, QCI]), columns=[\"\"], index=[\"DA\", \"QCI\"])\n",
    "\n",
    "    # Apply color and formatting to metrics table\n",
    "    style_table = (\n",
    "        metrics.style.format(\"{:.2f}\")\n",
    "        .applymap(color_value)\n",
    "        .highlight_null(null_color=\"gray\")\n",
    "        .render()\n",
    "    )\n",
    "\n",
    "    # Store content to be displayed in the dashboard\n",
    "    content = {\"table\": style_table}\n",
    "    return content\n",
    "\n",
    "\n",
    "def Milestone3_Get_Imported_OpenAQ_DatasetOutlier(OpenAQ_QC_Dataset):\n",
    "    \n",
    "   Delta = \"Check for stagnant data and/or abrupt changes in the data using the difference between max and min values (delta) within a rolling window\"\n",
    "      \n",
    "   UpperBound = \"Check for data that is outside expected range and Upper Bound\"\n",
    "   \n",
    "   LowerBound = \"Check for data that is outside expected range for Lower Bound\"\n",
    "   \n",
    "   Increment = \"Check data increments using the difference between values\"\n",
    "\n",
    "   Timestamp = \"Check time series for missing, non-monotonic and duplicate timestamps\"\n",
    "   \n",
    "   Outlier = \"Check for outliers using normalized data within a rolling window The upper and lower bounds are specified in standard deviations. Data normalized using (data-mean)/std.\"\n",
    "   \n",
    "   FunctionModel = \"Analyse\"\n",
    "   \n",
    "   NotComplete = \"Check for missing data\"\n",
    "    \n",
    "   QCI = \"QCI \"\n",
    " \n",
    "   if(OpenAQ_QC_Dataset == 0):\n",
    "\n",
    "       print(\"Criteria 1 Time Stamp\")\n",
    "       \n",
    "       print(Timestamp)\n",
    "\n",
    "       print(\"Criteria 2 Upper Lower Bound\")\n",
    "\n",
    "       print(UpperBound)\n",
    "       \n",
    "       print(LowerBound)\n",
    "       \n",
    "       print(\"Criteria 3 Delta \")\n",
    "\n",
    "       print(Delta)\n",
    "       \n",
    "       print(\"Criteria 4 Increment\")\n",
    "\n",
    "       print(Increment)\n",
    "       \n",
    "       print(\"Criteria 5 Outlier\")\n",
    "\n",
    "       print(Outlier)\n",
    "       \n",
    "       print(\"Criteria 6 Model Function\")\n",
    "\n",
    "       print(FunctionModel)\n",
    "       \n",
    "       print(\"Criteria 7 Missing Dataset\")\n",
    "\n",
    "       print(NotComplete)\n",
    "   \n",
    "       print(\"Performance Metric QCI \")\n",
    "\n",
    "       print(QCI)\n",
    "    \n",
    "def Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQDatasetSelect): \n",
    "    \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = '' # ../Milestone1_Importing-datasets-from-OpenAQ/'\n",
    "   \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = OpenAQ_Dataset_LatlngCSV_Download + OpenAQDatasetSelect\n",
    "   \n",
    "   ImportOpenAQimported = pd.read_csv(OpenAQ_Dataset_LatlngCSV_Download) \n",
    "   \n",
    "   print(ImportOpenAQimported['parameter'])\n",
    "  \n",
    "   return ImportOpenAQimported \n",
    "\n",
    "def Milestone3_Get_Imported_OpenAQ_Dataset_OpenAQDataset_Test(): \n",
    "    \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = '../Milestone1_Importing-datasets-from-OpenAQ/OpenAQ_Dataset1pm25Country2018-03-01to2020-09-01.csv'\n",
    "       \n",
    "   ImportOpenAQimported = pd.read_csv(OpenAQ_Dataset_LatlngCSV_Download)\n",
    "    \n",
    "   print(ImportOpenAQimported['parameter'])\n",
    " \n",
    "   return ImportOpenAQimported \n",
    "\n",
    "def Milestone3_Get_OpenAQresults(OpenAQDFResults, OpenAQDataset, QCI):\n",
    "  \n",
    "   OpenAQappend = [] \n",
    "\n",
    "   OpenAQmetric = []\n",
    "\n",
    "   for Outlier, df in OpenAQDFResults.groupby('Error Flag'):\n",
    "\n",
    "     \n",
    "      print(Outlier)   \n",
    "    \n",
    "      print(len(df))\n",
    "    \n",
    "      OpenAQappend.append(len(df)) \n",
    "      \n",
    "      OpenAQappend.append(str(Outlier))\n",
    "     \n",
    "   OpenAQappend.append(\"QCI\")   \n",
    " \n",
    "   OpenAQappend.append(QCI.value)\n",
    "   \n",
    "   \n",
    "   OpenAQDatsetappend = pd.DataFrame(OpenAQappend)\n",
    "        \n",
    "   return OpenAQDatsetappend \n",
    "\n",
    "OpenAQDataset_VisualAnalytics_Results = []\n",
    "\n",
    "# Step 1 Get Measurements from openAQ API \n",
    "#\n",
    "#  1 Change the OpenAQ dataset CSV to latest downloaded from Milestone 1 Using Cooridnate and Radius \n",
    "#\n",
    "#    Change OpenAQDatasetSelected to OpenAQ Dataset \n",
    "#\n",
    "#    The address is printed out after completing Milestone 1 Process\n",
    "#\n",
    "#  2 Add unique iteration \n",
    "#   \n",
    "#      edit  iteration_OpenAQStations = '0'\n",
    "#\n",
    "#\n",
    "#  3  \n",
    "#    Add in Coordinates and Radius\n",
    "#       \n",
    "#\n",
    "#  Limitations\n",
    "#\n",
    "#   It must be the OpenAQ Dataset downloaded using Coordinate and Radius \n",
    "#\n",
    "#  Test \n",
    "#\n",
    "#\n",
    "#  OpenAQDatasetSelected_Test = 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "#\n",
    "#  Milestone3_Get_Imported_OpenAQ_Dataset_Test(OpenAQDatasetSelected_Test, 1, \"Test Coordindate\")\n",
    "\n",
    "print(\"  STEP 1 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Getting Measurements from OpenAQ API source imported in Milestone 1 from Coordinate and Radius\")\n",
    "\n",
    "#### Edit \n",
    "\n",
    "OpenAQDatasetSelected = \"\" # \"OpenAQ_Dataset unique debugged['BE', 'AE'] pm25 Country 2020-03-01 to 2020-03-04.csv\" # 'OpenAQ_Dataset unique debugBE pm25 Country 2020-03-01 to 2020-03-04.csv' # 'OpenAQ_Dataset Unique selection pm25 One Station 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "\n",
    "# 'OpenAQ_Dataset Unique selection 24.4244 54.43375 pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "\n",
    "# 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv' # 'OpenAQ_Dataset AT4S406 pm25.csv' # 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "ImportedOpenAQimport = Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQDatasetSelected)\n",
    "\n",
    "\n",
    "print(ImportedOpenAQimport)\n",
    "\n",
    "print(\"Choosen Unique Iteration \")\n",
    "\n",
    "iteration_OpenAQStations = '1'  #Edit \n",
    "\n",
    "print(iteration_OpenAQStations)\n",
    "\n",
    "print(\"Chosen OpenAQ Coordinates and Radius: \")\n",
    "     \n",
    "OpenAQStationCountry = \"default 24.4244,54.43375\" #Edit\n",
    "\n",
    "Radius = 25000 # Edit in metres \n",
    "\n",
    "print(\"Completed Step 1 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "\n",
    "print(\"  STEP 2 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"OpenAQ Dataset imported \")\n",
    "\n",
    "print(OpenAQDatasetSelected)\n",
    "\n",
    "print(ImportedOpenAQimport.dtypes)\n",
    "\n",
    "\n",
    "print(\"Completed Step 2 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "print(\"  STEP 3 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "\n",
    "print(\"Found these Stations from Coordinates\")\n",
    "\n",
    "OpenAQStationunique = ImportedOpenAQimport['location'].unique()\n",
    "\n",
    "print(OpenAQStationunique)\n",
    "\n",
    "\n",
    "print(\"Completed Step 3 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "\n",
    "print(\"  STEP 4 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "# Step 4 Find the parameter of OpenAQ Dataset\n",
    "#\n",
    "#  1 Edit to default parameter if not in OpenAQ dataset\n",
    "#\n",
    "# Test \n",
    "#\n",
    "#  1 That is only one parameter \n",
    "# \n",
    "#\n",
    "print(\"Parameter\")\n",
    "\n",
    "Parameter_Default = 'pm25' # Edit\n",
    "\n",
    "OnlyOneParameter = 0 # Edit 0 - No and 1 Yes\n",
    "\n",
    "\n",
    "if(OnlyOneParameter == 1):\n",
    "    ImportedOpenAQimport = Milestone1_Get_Parameter(ImportedOpenAQimport, Parameter_Default)\n",
    "\n",
    "    parameter_selection = []\n",
    "    \n",
    "    parameter_selection.append(Parameter_Default)\n",
    "\n",
    "else:\n",
    "  \n",
    "    parameter_selection = ImportedOpenAQimport['parameter'].unique()\n",
    "\n",
    "print(\"Completed Step 4 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "#Step 5 Finding time schedule \n",
    "#\n",
    "# \n",
    "# 1 Change default Time Schedule from 6 months to other in dt_begin\n",
    "#  and dt_end\n",
    "#\n",
    "#  dt_begin =  date(2020,3,1) 1 March 2020 \n",
    "#\n",
    "#  dt_end =  date(2020,9,1) 1 September 2020\n",
    "#\n",
    "# Change these\n",
    "#\n",
    "# dt1begin = date(2020,3,1) # Edit\n",
    "#\n",
    "# dt1end = date(2020,9,1) # Edit\n",
    "#\n",
    "# dt_begin = dt1begin\n",
    "#\n",
    "# dt_end = dt1end\n",
    "\n",
    "print(\"  STEP 5 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "ChooseTimeScheduleNoorYes = 0 # Edit 0 No and 1 Yes  \n",
    "\n",
    "dt_begin = min(ImportedOpenAQimport['date.utc'])\n",
    "\n",
    "dt_end = max(ImportedOpenAQimport['date.utc'])\n",
    "\n",
    "\n",
    "if(ChooseTimeScheduleNoorYes == 1):\n",
    "\n",
    "  dt_begin = date(2020,3,1)\n",
    "    \n",
    "  dt_end = date(2020,9,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(dt_begin)\n",
    "print(\" to \")\n",
    "print(dt_end)\n",
    "print(\" for one OpenAQ Stations and one parameter \")\n",
    "\n",
    "\n",
    "print(\"Completed Step 5 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "# Step 6 Choose to remove measurement that have -999.00\n",
    "#\n",
    "# 1 It only removes -999.0 that are missing measurements \n",
    "#\n",
    "#  Edit the Remove_Neg to either\n",
    "#\n",
    "#   1 - Remove -999.0 from dataset \n",
    "# \n",
    "#   0 - Don't remove -999.0 from dataset\n",
    "#\n",
    "#  i.e Change to chosen\n",
    "# \n",
    "#   Remove_Neg = 1\n",
    "#\n",
    "#  2 Choose to remove negative measurements \n",
    "#\n",
    "#  Change  Remove_Negative_Measurements\n",
    "#  \n",
    "#   1 - Remove negative measurements \n",
    "\n",
    "\n",
    "print(\"  STEP 6 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Choose to remove missing measurements that are -999.0 and below 0\")\n",
    "\n",
    "Remove_Neg = 1 # Edit      Removes Only measurements of -999.0 \n",
    "\n",
    "Remove_Negative_Measurements = 1 # Edit Remove measure below 0 \n",
    "\n",
    "Remove_Neg_NO = 0\n",
    "\n",
    "Remove_Neg_YES = 1\n",
    "\n",
    "if(Remove_Neg == Remove_Neg_YES):\n",
    "  ImportedOpenAQimport = Milestone2_Remove_neg_attribute(ImportedOpenAQimport)\n",
    "  print(\"Removing missing measurements that are -999.0\")\n",
    "else:\n",
    "  print(\"Not removing missing measurements that are -999.0\")  \n",
    "  \n",
    "if(Remove_Negative_Measurements == Remove_Neg_YES):\n",
    "  ImportedOpenAQimport = Milestone2_Remove_negative_attribute(ImportedOpenAQimport)\n",
    "  print(\"Removing measurement below 0\")\n",
    "  \n",
    "  \n",
    "\n",
    "print(\"Completed Step 6 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "# Step 7 Do Data Wrangling on OpenAQ dataset  \n",
    "#\n",
    "# 1 It convert utc to DateTime for Pecos Quality Control and utc to index\n",
    "#\n",
    "#   \n",
    "  \n",
    "\n",
    "print(\"  STEP 7 \")\n",
    "\n",
    "print(\"********\")\n",
    "  \n",
    "print(\"Data Wrangling OpenAQ dataset evaluating UTC date to Date format and setting utc to index\")\n",
    "\n",
    "ImportedOpenAQimport = Milestone2_Get_OpenAQ_Dataset_Wrangling_utc_index(ImportedOpenAQimport)\n",
    "  \n",
    "\n",
    "print(\"Dataset Wrangling Completed\")\n",
    "\n",
    "print(\"OpenAQ Dataset imported \")\n",
    "\n",
    "print(ImportedOpenAQimport.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Completed Step 7 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "# Step 8 Import just Measurements to Dataframe with Date utc index for applying \n",
    "\n",
    "print(\"  STEP 8 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Get measurement to Dataframe\")\n",
    "\n",
    "OpenAQAPIdataset = pd.DataFrame(ImportedOpenAQimport, columns=['value','location','unit','parameter'])\n",
    "\n",
    "print(\"Completed Step 8 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "\n",
    "\n",
    "#Step 9 Plot OpenAQ Dataset to Line plot and Histogram\n",
    "\n",
    "print(\"  STEP 9 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Graph of OpenAQ Dataset Measumrents\")\n",
    "\n",
    "OpenAQ_unit = str(ImportedOpenAQimport['unit'][0]) \n",
    "\n",
    "OpenAQDataset_VisualAnalytics = \"OpenAQ Dataset QC\" + \" \" + \" Time Schedule \" + str(dt_begin) + \" to \" + str(dt_end)\n",
    "\n",
    "OpenAQDataset_VisualAnalytics_iteration = \"OpenAQDataset QC \" + \" \"  + \" iteration \" + iteration_OpenAQStations\n",
    "\n",
    "OpenAQDataset = Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram_Unique(OpenAQAPIdataset, OpenAQStationunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration)\n",
    "\n",
    "# Milestone3_Get_Imported_OpenAQ_Dataset_parameter_unique_Test(ImportedOpenAQimport,OpenAQDataset, 1,\"Test unique parameter\")\n",
    "\n",
    "\n",
    "print(\"Completed Step 9 \")\n",
    "\n",
    "print(\">\")\n",
    "\n",
    "\n",
    "# Step 10 Completing the Pecos Quality Control \n",
    "#\n",
    "#  1 The Search Criteria are edited in the Method \n",
    "#\n",
    "#  Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation\n",
    "#\n",
    "#  2 To incude completeness test to 1\n",
    "#\n",
    "#  Edit  QC_CheckDatasetComplete\n",
    "#\n",
    "#  3 To use YAML for Search Criteria \n",
    "#\n",
    "#  Change yaml_Yes to 1  \n",
    "#\n",
    "\n",
    "\n",
    "print(\"  STEP 10 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Get Pecos Quality Control on OpenAQ dataset\")\n",
    "\n",
    "yaml_Yes = 1\n",
    "\n",
    "\n",
    "DASHBOARDPATH = f\"openaq_dashboard.html\"\n",
    "\n",
    "\n",
    "QC_CheckDatasetComplete = 0 # To incude completeness test - 0 - To include  1 - To not include  \n",
    "\n",
    "print(\"OpenAQ Pecos Quality Control Search Criteria: \")\n",
    "\n",
    "\n",
    "\n",
    "Milestone3_Pecos_Complete_QC_QualityControl_OpenAQStation(ImportedOpenAQimport, OpenAQDataset_VisualAnalytics_iteration, OpenAQStationunique, OpenAQDataset, yaml_Yes)\n",
    "\n",
    "create_pecos_dashboard(parameter_selection, OpenAQStationunique, DASHBOARDPATH)\n",
    "\n",
    "\n",
    "\n",
    "print(\" **** \")\n",
    "\n",
    "OpenAQ_QC_Dataset = 0\n",
    "\n",
    "Milestone3_Get_Imported_OpenAQ_DatasetOutlier(OpenAQ_QC_Dataset)\n",
    "\n",
    "print(\" Results in Monitoring report\")\n",
    "\n",
    "for OpenAQDataset in OpenAQDataset_VisualAnalytics_Results:\n",
    "    \n",
    "   print(OpenAQDataset)\n",
    "\n",
    "print(\"Completed Step 10\")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-paintball",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dashboard_content = {}  # Initialize the dashboard content dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-blond",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_Get_OpenAQ_Dataset_Wrangling_utc_index(OpenAQ_Dataset_ImportAPI):\n",
    "\n",
    "   format = '%Y-%m-%d %H:%M:%S'\n",
    "    \n",
    "   OpenAQ_Dataset_ImportAPI['date.utc'] = pd.to_datetime(OpenAQ_Dataset_ImportAPI['date.utc'], format=format).dt.tz_localize(None)\n",
    "\n",
    "  # OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value != -999.00]\n",
    "\n",
    "   Formating = pd.DatetimeIndex(OpenAQ_Dataset_ImportAPI['date.utc'])\n",
    "  \n",
    "   OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI.set_index(Formating)\n",
    "\n",
    "   return OpenAQ_Dataset_ImportAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-perfume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_Remove_neg_attribute(OpenAQ_Dataset_ImportAPI):\n",
    "    \n",
    "    OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value != -999.00]\n",
    "\n",
    "    return OpenAQ_Dataset_ImportAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-lawrence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-commitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_Remove_negative_attribute(OpenAQ_Dataset_ImportAPI):\n",
    "    \n",
    "    OpenAQ_Dataset_ImportAPI = OpenAQ_Dataset_ImportAPI[OpenAQ_Dataset_ImportAPI.value >= 0]\n",
    "\n",
    "    return OpenAQ_Dataset_ImportAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-casting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram_Unique(df4, OpenAQStationunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration):\n",
    "   \n",
    "   OpenAQ_Dataset_Graph_df = [] \n",
    "    \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "      \n",
    "      OpenAQ_Dataset_Graph = []  \n",
    "      \n",
    "      OpenAQ_Dataset_Graph.append(OpenAQunique)\n",
    "      \n",
    "      OpenAQAPIdatasetunique = df4[df4['location'] == OpenAQunique]\n",
    "      \n",
    "      OpenAQStationcompletegetunique = Milestone2_OpenAQStation_remove_NonAlpha(OpenAQunique)\n",
    "            \n",
    "      OpenAQDataset_measureStationVisualAnalytics = OpenAQDataset_VisualAnalytics + \" Station OpenAQ \" + OpenAQStationcompletegetunique\n",
    "      \n",
    "      OpenAQDataset_VisualGraphiteration = OpenAQDataset_VisualAnalytics_iteration + \" Station OpenAQ \" + OpenAQStationcompletegetunique\n",
    "            \n",
    "      OpenAQgraph = Milestone2_OpenAQ_VisualAnalytics_parameters(OpenAQAPIdatasetunique, OpenAQunique, OpenAQDataset_measureStationVisualAnalytics, OpenAQDataset_VisualGraphiteration)\n",
    "      \n",
    "      OpenAQ_Dataset_Graph.append(OpenAQgraph)\n",
    "\n",
    "      OpenAQ_Dataset_Graph_df.append(OpenAQ_Dataset_Graph)\n",
    "\n",
    "   return OpenAQ_Dataset_Graph_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-onion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Milestone2_OpenAQ_VisualAnalytics_parameters(df4,OpenAQselectunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration):\n",
    "        \n",
    "        \n",
    "    OpenAQparameterunique = df4['parameter'].unique()\n",
    "    \n",
    "    OpenAQ_Dataset_uniqueGraph = []  \n",
    "    \n",
    "    \n",
    "    for OpenAQStationparameter in OpenAQparameterunique:\n",
    "        \n",
    "       OpenAQ_Dataset_Graph = []  \n",
    "       \n",
    "       OpenAQ_Dataset_Graph.append(OpenAQselectunique)\n",
    "       \n",
    "      \n",
    "       OpenAQdfunique = df4[df4['parameter'] == OpenAQStationparameter]\n",
    "       \n",
    "       OpenAQDataset_VisualAnalyticsplt = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationparameter\n",
    "       \n",
    "       OpenAQDataset_VisualAnalytic = OpenAQDataset_VisualAnalytics + \" \" + OpenAQStationparameter\n",
    "       \n",
    "       yaxishistogram = \"Amount of Measurements \" + OpenAQStationparameter\n",
    "              \n",
    "       OpenAQ_Dataset_df = Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram(OpenAQdfunique, OpenAQStationparameter, OpenAQDataset_VisualAnalyticsplt, title=OpenAQDataset_VisualAnalytic, xlabel='Value', ylabel=yaxishistogram, dpi=100)\n",
    "      \n",
    "       OpenAQ_Dataset_Graph.append(OpenAQ_Dataset_df)\n",
    "      \n",
    "       yaxis = \"OpenAQ Measurements \" + OpenAQStationparameter\n",
    "       \n",
    "       OpenAQ_Dataset = Milestone2_Import_OpenAQ_CSV_plot(OpenAQdfunique, OpenAQdfunique.index, OpenAQdfunique['value'], OpenAQStationparameter, OpenAQDataset_VisualAnalyticsplt, title=OpenAQDataset_VisualAnalytic, xlabel='Date utc timestamp', ylabel=yaxis, dpi=100)\n",
    "\n",
    "       OpenAQ_Dataset_Graph.append(OpenAQ_Dataset)\n",
    "\n",
    "       OpenAQ_Dataset_Graph.append(OpenAQStationparameter)\n",
    "\n",
    "       OpenAQ_Dataset_uniqueGraph.append(OpenAQ_Dataset_Graph) \n",
    "\n",
    "\n",
    "    OpenAQ_Dataset_uniqueGraph.append(OpenAQparameterunique)\n",
    "\n",
    "    return OpenAQ_Dataset_uniqueGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-tsunami",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_OpenAQStation_remove_NonAlpha(OpenAQStationunique):\n",
    "    \n",
    "   OpenAQStationformatunique = re.sub(r'\\W+', '', str(OpenAQStationunique))\n",
    "  \n",
    "   print(OpenAQStationformatunique)\n",
    "   \n",
    "   return OpenAQStationformatunique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-degree",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_Import_OpenAQ_CSV_plot_Unique(df4, OpenAQStationunique, xaxis, yaxis, parameter, OpenAQDataset_VisualAnalytics, xlabel='Value', ylabel='Amount of Measurements', dpi=100):\n",
    "   \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "        \n",
    "      print(OpenAQunique) \n",
    "       \n",
    "      OpenAQAPIdatasetunique = df4[df4['location'] == OpenAQunique]\n",
    "      \n",
    "      Milestone2_Import_OpenAQ_CSV_plot(OpenAQAPIdataset, xaxis, yaxis, parameter, OpenAQ_Dataset, title=OpenAQDataset_VisualAnalytics, xlabel='Value', ylabel='Amount of Measurements', dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-destruction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram(df4, parameter, OpenAQDataset_VisualAnalytics_iteration, title=\"\", xlabel='Value', ylabel='Amount of Measurements', dpi=100):\n",
    "    \n",
    "# Step Create a Histogram of the OpenAQ Dataset for parameter\n",
    "   \n",
    "   print(\"Histogram of OpenAQ Dataset from OpenAQ API download\") \n",
    "    \n",
    "   plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "   \n",
    "   plt.hist(df4['value'], bins=\"auto\")\n",
    "            \n",
    "           # bins=np.arange(1,df4['value'].max()))\n",
    "   \n",
    "   OpenAQ_Dataset =  OpenAQDataset_VisualAnalytics_iteration + \" Histogram\" + \".png\"\n",
    "      \n",
    "   plt.savefig(OpenAQ_Dataset)\n",
    "   \n",
    "   plt.show()\n",
    "\n",
    "   return OpenAQ_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone2_Import_OpenAQ_CSV_plot(df4, xaxis, yaxis, parameter, OpenAQDataset_VisualAnalytics_iteration,  title=\"\", xlabel='Date', ylabel='Value', dpi=100):\n",
    "    \n",
    "   print(\"OpenAQ Dataset LinePlot\")\n",
    "     \n",
    "   plt.figure(figsize=(16,5), dpi=dpi)\n",
    "   plt.plot(xaxis, yaxis, color='tab:blue')\n",
    "   plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)\n",
    "       \n",
    "   OpenAQ_Dataset = OpenAQDataset_VisualAnalytics_iteration + \" Line Graph\" + \".png\"\n",
    "        \n",
    "   plt.savefig(OpenAQ_Dataset)\n",
    " \n",
    "   plt.show()\n",
    "\n",
    "   return OpenAQ_Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-understanding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone1_Get_Parameter(DatasetOpenAQ, Parameter):\n",
    "       \n",
    "   DatasetOpenAQ = DatasetOpenAQ[DatasetOpenAQ.parameter==Parameter]\n",
    "  \n",
    "   return DatasetOpenAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-kelly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Imported_OpenAQ_Dataset_parameter_unique_Test(OpenAQDatasetparameter, OpenAQ_Dataset_Graph_df, TestId, Test_Analysis):\n",
    "    \n",
    "   OpenAQStationparameter = OpenAQDatasetparameter['parameter'].unique()\n",
    "\n",
    "\n",
    "   for OpenAQStation in OpenAQ_Dataset_Graph_df:\n",
    "       \n",
    "      print(OpenAQStation[1][1])    \n",
    "      \n",
    "      \n",
    "\n",
    "   if(len(OpenAQStationparameter) == 0):\n",
    "     parameter = OpenAQStationparameter[0]\n",
    "  \n",
    "   else:\n",
    "     parameter = Parameter_Default  \n",
    "    \n",
    "   return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-numbers",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-mechanics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Imported_OpenAQ_Dataset_Test(OpenAQ_Dataset_OpenAQCSV_Download_Test, TestId, Test_Analysis):\n",
    "    \n",
    "   Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQ_Dataset_OpenAQCSV_Download_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-vatican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_VisualAnalytics(OpenAQDataset, OpenAQStation):\n",
    "     \n",
    "    OpenAQdfDataset = []\n",
    "    \n",
    "    for OpenAQdatasetGraph in OpenAQDataset:\n",
    "      \n",
    "       if(OpenAQdatasetGraph[0] == OpenAQStation): \n",
    "\n",
    "           OpenAQdfDataset = OpenAQdatasetGraph\n",
    "           \n",
    "    return OpenAQdfDataset       \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-christianity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Pecos_Complete_QC_QualityControl_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQStationunique, OpenAQDataset, yaml_include):\n",
    "    \n",
    "   iteration = 0 \n",
    "    \n",
    "   OpenAQSearchCriteria = \"\"\n",
    "    \n",
    "   for OpenAQunique in OpenAQStationunique:\n",
    "        \n",
    "      print(OpenAQunique) \n",
    "   \n",
    "      OpenAQSearchCriteria = OpenAQSearchCriteria + \"\"\n",
    "      \n",
    "      OpenAQAPIdatasetunique = OpenAQStation[OpenAQStation['location'] == OpenAQunique]\n",
    "      \n",
    "      OpenAQCompleteDataset = Milestone3_Get_VisualAnalytics(OpenAQDataset, OpenAQunique)\n",
    "      \n",
    "      OpenAQStationcompleteunique = Milestone2_OpenAQStation_remove_NonAlpha(OpenAQunique)\n",
    "      \n",
    "      OpenAQDataset_VisualAnalytics_iteration_unique = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationcompleteunique \n",
    "      \n",
    "      Milestone3_Pecos_Quality_Control_parameters(OpenAQStation[OpenAQStation['location']==OpenAQunique], OpenAQDataset_VisualAnalytics_iteration_unique, OpenAQDataset[iteration][1], OpenAQSearchCriteria, yaml_include, OpenAQunique)\n",
    "\n",
    "      iteration = iteration + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-problem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Pecos_Quality_Control_parameters(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset, OpenAQSearchCriteria, yaml_include, OpenAQunique):\n",
    "    \n",
    "    OpenAQparameterunique = OpenAQStation['parameter'].unique()\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    for OpenAQStationparameter in OpenAQparameterunique:\n",
    "        \n",
    "       OpenAQSearchCriteria1 = OpenAQSearchCriteria + \"\" + OpenAQStationparameter\n",
    "        \n",
    "       OpenAQDatasetStation = Milestone1_Get_Parameter(OpenAQStation, OpenAQStationparameter)\n",
    "\n",
    "       OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration + \" \" + OpenAQStationparameter \n",
    "\n",
    "       if(yaml_include == 1):\n",
    "   \n",
    "           (DA, QCI) =Milestone3_Pecos_Complete_QualityControl_SearchCriteriaOne_OpenAQStation(OpenAQDatasetStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset[iteration], OpenAQSearchCriteria1)\n",
    "           dashboard_cell = generate_dashboard_cell(DA, QCI)\n",
    "           dashboard_content[(OpenAQunique, OpenAQStationparameter)] = dashboard_cell\n",
    "           \n",
    "       else:    \n",
    " \n",
    "           (DA, QCI) = Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation(OpenAQDatasetStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset[iteration]) \n",
    "           dashboard_cell = generate_dashboard_cell(DA, QCI)\n",
    "           dashboard_content[(OpenAQunique, OpenAQStationparameter)] = dashboard_cell\n",
    "          \n",
    "       iteration = iteration + 1        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-moment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset):\n",
    "\n",
    "   # Step 2 Initialize logger and Create a Pecos PerformanceMonitoring data object\n",
    "   pecos.logger.initialize()\n",
    "   \n",
    "   pm = pecos.monitoring.PerformanceMonitoring()\n",
    "\n",
    "   print()\n",
    "\n",
    "   # Step 3 Append Dataframe to Pecos PerformanceMonitoring data object\n",
    "   pm.add_dataframe(OpenAQStation)\n",
    "\n",
    "   # Step 4 Check the expected frequency of the timestamp\n",
    "   #\n",
    "   # 1 Edit timestep when 900 is 15 mins     \n",
    "\n",
    "   Timestep = 900 # Edit\n",
    "   \n",
    "   pm.check_timestamp(Timestep)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 1 : Timestep \")\n",
    "   \n",
    "   print(Timestep)\n",
    "   \n",
    "   # Step 5 Check for missing data\n",
    "   \n",
    "   \n",
    "   no_missing_values = OpenAQStation.value.isna().sum()\n",
    "   data_availability = (len(OpenAQStation.index) - no_missing_values) / len(OpenAQStation.index)\n",
    "\n",
    "   print(\"data availabilty: \", no_missing_values, data_availability)\n",
    "\n",
    "   \n",
    "   if(QC_CheckDatasetComplete == 1):\n",
    "\n",
    "       pm.check_missing()\n",
    "   \n",
    "# Step 6 Choose acceptable value range and Check data for expected ranges\n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound of values\n",
    "#  2 Higher Bound of values\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Minimum number of consecutive failures for reporting (default = 1)le increment from measurements of 15 minutes and check for abrupt changes between consecutive time steps\n",
    "#\n",
    "#   e.g pm.check_range([0, 200], key='value')  \n",
    "#         pm.check_range([1, 2], key='3',4)\n",
    "#\n",
    "# Results: Any value outside of the range is an outlier\n",
    "\n",
    "   LowerBound = None # Edit \n",
    "   \n",
    "   HigherBound = 400 # Edit\n",
    "\n",
    "   pm.check_range([LowerBound, HigherBound], key='value')\n",
    " \n",
    "   print(\"*****\")\n",
    "   \n",
    "   print(\"Criteria 2 : Lower Bound and Higher Bound \")\n",
    "  \n",
    "   print(\"Lower Bound \")\n",
    "   \n",
    "   print(LowerBound)   \n",
    "   \n",
    "   print(\"Higher Bound\")\n",
    "   \n",
    "   print(HigherBound)\n",
    "   \n",
    "# Step 7 Choose the min amount that is acceptable to change from measurements \n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "#    1 Lower bound to decrease by\n",
    "#    2 Upper bound to increase by\n",
    "#    3 Size of the moving window used to compute the difference between the minimum and maximum\n",
    "#    4 Data column (default = None, which indicates that all columns are used)\n",
    "#    5 Flag indicating if the test should only check for positive delta (the min occurs before the max) or negative delta (the max occurs before the min) (default = False)\n",
    "#    6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "#  e.g. pm.check_delta([Miniumn Decrease, Min Increase], window=3600, 'value')\n",
    "#      included parametes 1-6: pm.check_delta([1, 2], window=3, key='4', 5, 6)\n",
    "#\n",
    "#  Results: When over min decrease or increase it is an outlier\n",
    " \n",
    "   print(\"*****\")\n",
    "  \n",
    "   print(\"Criteria 3 : Stagnant Measurements \")\n",
    "  \n",
    "   DeltaLowerBound = None # Edit\n",
    "   \n",
    "   DeltaHigherBound = 10 # Edit\n",
    "   \n",
    "   DeltaTimeSchedule = 3600 # Edit\n",
    "   \n",
    "   pm.check_delta([DeltaLowerBound, DeltaHigherBound], window=DeltaTimeSchedule, key='value')\n",
    "\n",
    "   print(\" Measurement that increase by \" )\n",
    "   \n",
    "   print(DeltaHigherBound )\n",
    "   \n",
    "   print(\"in Time Schedule\")\n",
    "   \n",
    "   print(DeltaTimeSchedule)\n",
    "\n",
    "   print(\"Delta Lower Bound\")\n",
    "\n",
    "   print(DeltaLowerBound)\n",
    "\n",
    "# Step 8 Choose acceptable increment on measurements \n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound to de increment by\n",
    "#  2 Higher Bound to increment by\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Increment used for difference calculation (default = 1 timestamp)\n",
    "#  5 Flag indicating if the absolute value of the increment is used in the test (default = True)\n",
    "#  6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "# e.g pm.check_increment([None, 20], 'value') \n",
    "#    included parametes 1- 4:  pm.check_increment([1, 2], key='3', 4, 5, 6) \n",
    "#\n",
    "# Results: Any measurement that has a larger increment or de increment by choosen value is an outlier\n",
    "\n",
    "   print(\"*****\")\n",
    " \n",
    "   print(\"Criteria 4 : Maximum Increment of Measurements \")\n",
    "\n",
    "   Increment_Increase = 20 # Edit\n",
    "   \n",
    "   Increment_Decrease = None # Edit\n",
    "  \n",
    "   pm.check_increment([Increment_Decrease, Increment_Increase], key='value') \n",
    "\n",
    "   print(\"Increment Increase\")\n",
    "   \n",
    "   print(Increment_Increase)\n",
    "\n",
    "   print(\"Increment Decrease\")\n",
    "   \n",
    "   print(Increment_Decrease)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 5: Outlier\")\n",
    "   \n",
    "   print(\"UpperBound\")\n",
    "\n",
    "   UpperBoundOutlier = 3 # Edit\n",
    "\n",
    "   LowerBoundOutlier = None # Edit\n",
    "   \n",
    "   print(UpperBoundOutlier)\n",
    "   \n",
    "   print(\"Time Schedule\")\n",
    "     \n",
    "   TimeSchedule = 12*3600 # Edit\n",
    "   \n",
    "   print(TimeSchedule)\n",
    "   \n",
    "   pm.check_outlier([LowerBoundOutlier, UpperBoundOutlier], window=TimeSchedule, key='value')\n",
    "\n",
    "   # Step 9 Compute the quality control index for value\n",
    "   mask = pm.mask[['value']]\n",
    "       \n",
    "   QCI = pecos.metrics.qci(mask)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"OpenAQ Dataset Results \")\n",
    "\n",
    "   print(\"Mask\")\n",
    "  \n",
    "   print(pm.mask) \n",
    "   \n",
    " #  print(pm.cleaned_data[pm.cleaned_data['value'] == 'NaN'])\n",
    "   \n",
    "   print(\"Performance Metrics\")\n",
    "\n",
    "   print(QCI)\n",
    "\n",
    "   custom = 'custom' + OpenAQDataset_VisualAnalytics_iteration + '.png'\n",
    "\n",
    "   custom_graphics_graph = '.png' \n",
    "\n",
    "   MeasurementOpenAQ = int(OpenAQStation['value'].max())\n",
    "\n",
    "   print(OpenAQStation['value'].describe())\n",
    "  \n",
    "    \n",
    "   test_results_graphics_OpenAQ = [] \n",
    "   \n",
    "   # Step 10 Generate graphics\n",
    "   test_results_graphics = pecos.graphics.plot_test_results(pm.df, pm.test_results, filename_root=OpenAQDataset_VisualAnalytics_iteration)\n",
    "   \n",
    "   \n",
    "   \n",
    " #  test_results_graphics_OpenAQ.append(test_results_graphics)\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[1])\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[2])\n",
    "\n",
    "   \n",
    "   OpenAQStation.plot(y='value', ylim=[0,MeasurementOpenAQ], figsize=(7.0,3.5))\n",
    "   plt.savefig(custom, format='png', dpi=500)\n",
    "\n",
    "   print(custom)\n",
    " \n",
    "   test_results_graphics_OpenAQ.append(custom)\n",
    "   \n",
    "   print(pm.test_results)\n",
    " \n",
    " #  OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration \n",
    "\n",
    "   # Step 11 Write test results and report files to test_results.csv and monitoringreport.html\n",
    "\n",
    "   Report = 'test_results' + OpenAQDataset_VisualAnalytics_iteration  + ' Result' + '.csv' \n",
    "\n",
    "   MonitoringReport = 'MonitoringReport' + OpenAQDataset_VisualAnalytics_iteration + '.html'\n",
    "\n",
    "   pecos.io.write_test_results(pm.test_results,filename=Report)\n",
    "   pecos.io.write_monitoring_report(pm.df, pm.test_results, test_results_graphics, \n",
    "                                 test_results_graphics_OpenAQ, QCI,filename=MonitoringReport)\n",
    " \n",
    "   metricsOpenAQ = Milestone3_Get_OpenAQresults(pm.test_results, pm.df, QCI)   \n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(Report)\n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(MonitoringReport)\n",
    "   \n",
    " #  OpenAQDataset_VisualAnalytics_Results.append(OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv')\n",
    "  \n",
    "  # pecos.io.write_metrics(metricsOpenAQ, OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv') \n",
    "\n",
    "   return (data_availability, QCI.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-union",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria):\n",
    "  \n",
    "   if(yaml_Yes == 1):\n",
    "       \n",
    "     import yaml \n",
    "  \n",
    "     config_file = OpenAQSearchCriteria + '_config.yml'\n",
    "     fid = open(config_file, 'r')\n",
    "     config = yaml.load(fid)\n",
    "     fid.close()\n",
    "   else:\n",
    "     \n",
    "     config = PecosQC\n",
    "       \n",
    "   return config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-separate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-agriculture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Pecos_Complete_QualityControl_SearchCriteriaOne_OpenAQStation(OpenAQStation, OpenAQDataset_VisualAnalytics_iteration, OpenAQDataset, OpenAQSearchCriteria):\n",
    "\n",
    "   # Step 2 Initialize logger, Get search criteria and Create a Pecos PerformanceMonitoring data object\n",
    "   pecos.logger.initialize()\n",
    "   \n",
    "   PecosQualityControlSearchCriteria = Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria)\n",
    "  \n",
    "   pm = pecos.monitoring.PerformanceMonitoring()\n",
    "\n",
    "   # Step 3 Append Dataframe to Pecos PerformanceMonitoring data object\n",
    "   \n",
    "      \n",
    "   time_increment_mode = get_time_increment_mode(OpenAQStation)\n",
    "\n",
    "   \n",
    "   OpenAQStation = cleanup_dataframe(OpenAQStation, time_increment_mode)\n",
    "\n",
    "   pm.add_dataframe(OpenAQStation)\n",
    "\n",
    "   # Step 4 Check the expected frequency of the timestamp\n",
    "   #\n",
    "   # 1 Edit timestep when 900 is 15 mins     \n",
    "\n",
    "   Timestep = PecosQualityControlSearchCriteria['Criteria1Timestep']['Timestep'] \n",
    "   \n",
    "\n",
    "  \n",
    "   no_missing_values = OpenAQStation.value.isna().sum()\n",
    "   data_availability = (len(OpenAQStation.index) - no_missing_values) / len(OpenAQStation.index)\n",
    "\n",
    "   print(\"data availabilty: \", no_missing_values, data_availability)\n",
    "\n",
    "   \n",
    "\n",
    "   \n",
    "   # Default 900 # Edit\n",
    "   \n",
    "   pm.check_timestamp(Timestep)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 1 : Timestep \")\n",
    "   \n",
    "   print(Timestep)\n",
    "   \n",
    "   # Step 5 Check for missing data\n",
    "   \n",
    "   if(QC_CheckDatasetComplete == 1):\n",
    "\n",
    "       pm.check_missing()\n",
    "   \n",
    "# Step 6 Choose acceptable value range and Check data for expected ranges\n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound of values\n",
    "#  2 Higher Bound of values\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Minimum number of consecutive failures for reporting (default = 1)le increment from measurements of 15 minutes and check for abrupt changes between consecutive time steps\n",
    "#\n",
    "#   e.g pm.check_range([0, 200], key='value')  \n",
    "#         pm.check_range([1, 2], key='3',4)\n",
    "#\n",
    "# Results: Any value outside of the range is an outlier\n",
    "\n",
    "   LowerBound =  PecosQualityControlSearchCriteria['Criteria2LowerHigherBound']['LowerBound']\n",
    "   \n",
    "   # Defualt None # Edit \n",
    "   \n",
    "   HigherBound =  PecosQualityControlSearchCriteria['Criteria2LowerHigherBound']['HigherBound']\n",
    "      \n",
    "   # Default 400 # Edit\n",
    "\n",
    "   pm.check_range([LowerBound, HigherBound], key='value')\n",
    " \n",
    "   print(\"*****\")\n",
    "   \n",
    "   print(\"Criteria 2 : Lower Bound and Higher Bound \")\n",
    "  \n",
    "   print(\"Lower Bound \")\n",
    "   \n",
    "   print(LowerBound)   \n",
    "   \n",
    "   print(\"Higher Bound\")\n",
    "   \n",
    "   print(HigherBound)\n",
    "   \n",
    "# Step 7 Choose the min amount that is acceptable to change from measurements \n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "#    1 Lower bound to decrease by\n",
    "#    2 Upper bound to increase by\n",
    "#    3 Size of the moving window used to compute the difference between the minimum and maximum\n",
    "#    4 Data column (default = None, which indicates that all columns are used)\n",
    "#    5 Flag indicating if the test should only check for positive delta (the min occurs before the max) or negative delta (the max occurs before the min) (default = False)\n",
    "#    6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "#  e.g. pm.check_delta([Miniumn Decrease, Min Increase], window=3600, 'value')\n",
    "#      included parametes 1-6: pm.check_delta([1, 2], window=3, key='4', 5, 6)\n",
    "#\n",
    "#  Results: When over min decrease or increase it is an outlier\n",
    " \n",
    "   print(\"*****\")\n",
    "  \n",
    "   print(\"Criteria 3 : Stagnant Measurements \")\n",
    "  \n",
    "   DeltaLowerBound =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['min']\n",
    "   \n",
    "   \n",
    "   # Default None # Edit\n",
    "   \n",
    "   DeltaHigherBound =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['max']\n",
    "   \n",
    "   # Default 10 # Edit\n",
    "   \n",
    "   DeltaTimeSchedule =  PecosQualityControlSearchCriteria['Criteria3Stagnant']['TimeSchedule']\n",
    "   \n",
    "   # Default 3600 # Edit\n",
    "      \n",
    "   MinbeforeMaxandMaxMin = PecosQualityControlSearchCriteria['Criteria3Stagnant']['MinbeforeMaxandMaxMin']\n",
    "     \n",
    "   MinConsectiveFailures = PecosQualityControlSearchCriteria['Criteria3Stagnant']['MinConsectiveFailures']  \n",
    "   \n",
    "   pm.check_delta([DeltaLowerBound, DeltaHigherBound], window=DeltaTimeSchedule, direction=MinbeforeMaxandMaxMin, min_failures=MinConsectiveFailures, key='value')\n",
    "\n",
    "   print(\" Measurement that increase by \" )\n",
    "   \n",
    "   print(DeltaHigherBound )\n",
    "   \n",
    "   print(\"in Time Schedule\")\n",
    "   \n",
    "   print(DeltaTimeSchedule)\n",
    "\n",
    "   print(\"Delta Lower Bound\")\n",
    "\n",
    "   print(DeltaLowerBound)\n",
    "\n",
    "# Step 8 Choose acceptable increment on measurements \n",
    "#\n",
    "# Parameters\n",
    "#  \n",
    "#  1 Lower bound to de increment by\n",
    "#  2 Higher Bound to increment by\n",
    "#  3 Data column (default = None, which indicates that all columns are used)\n",
    "#  4 Increment used for difference calculation (default = 1 timestamp)\n",
    "#  5 Flag indicating if the absolute value of the increment is used in the test (default = True)\n",
    "#  6 Minimum number of consecutive failures for reporting (default = 1)\n",
    "#\n",
    "# e.g pm.check_increment([None, 20], 'value') \n",
    "#    included parametes 1- 4:  pm.check_increment([1, 2], key='3', 4, 5, 6) \n",
    "#\n",
    "# Results: Any measurement that has a larger increment or de increment by choosen value is an outlier\n",
    "\n",
    "   print(\"*****\")\n",
    " \n",
    "   print(\"Criteria 4 : Maximum Increment of Measurements \")\n",
    "\n",
    "   Increment_Increase = PecosQualityControlSearchCriteria['Criteria4Increment']['max']\n",
    "   \n",
    "   # Default 20 # Edit\n",
    "   \n",
    "   Increment_Decrease = PecosQualityControlSearchCriteria['Criteria4Increment']['min']\n",
    "   \n",
    "   # Default None # Edit\n",
    "  \n",
    "   pm.check_increment([Increment_Decrease, Increment_Increase], key='value') \n",
    "\n",
    "   print(\"Increment Increase\")\n",
    "   \n",
    "   print(Increment_Increase)\n",
    "\n",
    "   print(\"Increment Decrease\")\n",
    "   \n",
    "   print(Increment_Decrease)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"Criteria 5: Outlier\")\n",
    "   \n",
    "   print(\"UpperBound\")\n",
    "\n",
    "   UpperBoundOutlier = PecosQualityControlSearchCriteria['Criteria5Outlier']['UpperBound']\n",
    "   \n",
    "   \n",
    "   # Default 3 # Edit\n",
    "\n",
    "   LowerBoundOutlier = PecosQualityControlSearchCriteria['Criteria5Outlier']['LowerBound']\n",
    "  \n",
    "   \n",
    "   # None # Edit\n",
    "   \n",
    "   print(UpperBoundOutlier)\n",
    "   \n",
    "   print(\"Time Schedule\")\n",
    "     \n",
    "   TimeSchedule = PecosQualityControlSearchCriteria['Criteria5Outlier']['TimeSchedule']\n",
    "   \n",
    "   # Default 12*3600 # Edit\n",
    "   \n",
    "   print(TimeSchedule)\n",
    "   \n",
    "   pm.check_outlier([LowerBoundOutlier, UpperBoundOutlier], window=TimeSchedule, key='value')\n",
    "\n",
    "   # Step 9 Compute the quality control index for value\n",
    "   mask = pm.mask[['value']]\n",
    "       \n",
    "   QCI = pecos.metrics.qci(mask)\n",
    "\n",
    "   print(\"*****\")\n",
    "\n",
    "   print(\"OpenAQ Dataset Results \")\n",
    "\n",
    "   print(\"Mask\")\n",
    "  \n",
    "   print(pm.mask) \n",
    "   \n",
    " #  print(pm.cleaned_data[pm.cleaned_data['value'] == 'NaN'])\n",
    "   \n",
    "   print(\"Performance Metrics\")\n",
    "\n",
    "   print(QCI)\n",
    "\n",
    "   custom = 'custom' + OpenAQDataset_VisualAnalytics_iteration + '.png'\n",
    "\n",
    "   custom_graphics_graph = '.png' \n",
    "\n",
    "   MeasurementOpenAQ = int(OpenAQStation['value'].max())\n",
    "\n",
    "   print(OpenAQStation['value'].describe())\n",
    "  \n",
    "    \n",
    "   test_results_graphics_OpenAQ = [] \n",
    "   \n",
    "   # Step 10 Generate graphics\n",
    "   test_results_graphics = pecos.graphics.plot_test_results(pm.df, pm.test_results, filename_root=OpenAQDataset_VisualAnalytics_iteration)\n",
    "   \n",
    "   \n",
    "   \n",
    " #  test_results_graphics_OpenAQ.append(test_results_graphics)\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[1])\n",
    "   \n",
    "   test_results_graphics_OpenAQ.append(OpenAQDataset[2])\n",
    "\n",
    "   \n",
    "   OpenAQStation.plot(y='value', ylim=[0,MeasurementOpenAQ], figsize=(7.0,3.5))\n",
    "   plt.savefig(custom, format='png', dpi=500)\n",
    "\n",
    "   print(custom)\n",
    " \n",
    "   test_results_graphics_OpenAQ.append(custom)\n",
    "   \n",
    "   print(pm.test_results)\n",
    " \n",
    " #  OpenAQDataset_VisualAnalytics_iteration = OpenAQDataset_VisualAnalytics_iteration \n",
    "\n",
    "   # Step 11 Write test results and report files to test_results.csv and monitoringreport.html\n",
    "\n",
    "   Report = 'test_results' + OpenAQDataset_VisualAnalytics_iteration  + ' Result' + '.csv' \n",
    "\n",
    "   MonitoringReport = 'MonitoringReport' + OpenAQDataset_VisualAnalytics_iteration + '.html'\n",
    "\n",
    "   pecos.io.write_test_results(pm.test_results,filename=Report)\n",
    "   pecos.io.write_monitoring_report(pm.df, pm.test_results, test_results_graphics, \n",
    "                                 test_results_graphics_OpenAQ, QCI,filename=MonitoringReport)\n",
    " \n",
    "   metricsOpenAQ = Milestone3_Get_OpenAQresults(pm.test_results, pm.df, QCI)   \n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(Report)\n",
    "   \n",
    "   OpenAQDataset_VisualAnalytics_Results.append(MonitoringReport)\n",
    "   \n",
    " #  OpenAQDataset_VisualAnalytics_Results.append(OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv')\n",
    "  \n",
    "  # pecos.io.write_metrics(metricsOpenAQ, OpenAQDataset_VisualAnalytics_iteration + 'metrics.csv') \n",
    "\n",
    "   return (data_availability, QCI.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pecos_dashboard(parameter_list, location_list, Dashboard):\n",
    "    footnote = \"DA = Data availability <br>QCI = Quality control index\"\n",
    "\n",
    "    for location in location_list:\n",
    "        for parameter in parameter_list:\n",
    "            if (location, parameter) not in dashboard_content:\n",
    "                dashboard_content[(location, parameter)] = \"&nbsp;\"\n",
    "\n",
    "    pecos.io.write_dashboard(\n",
    "        parameter_list,\n",
    "        location_list,dashboard_content,\n",
    "        footnote=footnote,\n",
    "        filename=Dashboard,\n",
    "    )\n",
    "    \n",
    "    OpenAQDataset_VisualAnalytics_Results.append(Dashboard)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-springfield",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Pecos_QualityControl_SearchCriteria(OpenAQSearchCriteria):\n",
    "  \n",
    "   if(yaml_Yes == 1):\n",
    "       \n",
    "     import yaml \n",
    "  \n",
    "     config_file = OpenAQSearchCriteria + \"_default\"  + '_config.yml'\n",
    "     fid = open(config_file, 'r')\n",
    "     config = yaml.load(fid)\n",
    "     fid.close()\n",
    "   else:\n",
    "     \n",
    "     config = PecosQC\n",
    "       \n",
    "   return config  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-trout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biological-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_value(val):\n",
    "\n",
    "    nThresholds = 10\n",
    "    colors = [(0.75, 0.15, 0.15), (1, 0.75, 0.15), (0.15, 0.75, 0.15)]\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        name=\"custom\", colors=colors, N=nThresholds\n",
    "    )\n",
    "\n",
    "    # print(\"color val\", val)\n",
    "    return_color = \"\"\n",
    "    if np.isnan(val):\n",
    "        return_color = \"background-color: gray\"\n",
    "    elif val > 1:\n",
    "        return_color = \"background-color: gray\"\n",
    "    elif val < 0:\n",
    "        return_color = \"background-color: gray\"\n",
    "    else:\n",
    "        binned_value = int(np.floor(val * 10))\n",
    "        rgb_color = cmap(binned_value)[:3]\n",
    "        hex_color = rgb2hex(rgb_color)\n",
    "        return_color = \"background-color: \" + hex_color\n",
    "\n",
    "    return return_color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-statistics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_dataframe(df, time_increment_mode):\n",
    "    \"\"\"replace OpenAQ missing value with np.nan and insert nans where ther are gaps\"\"\"\n",
    "    start_index = df.index[0]\n",
    "    end_index = df.index[-1]\n",
    "    idx = pd.date_range(\n",
    "        start_index, end_index, freq=\"{}S\".format(int(time_increment_mode))\n",
    "    )\n",
    "\n",
    "    df = df.reindex(idx, fill_value=np.nan)\n",
    "    # df.value.replace(-999, np.nan)\n",
    "    # df.value[df.value < 0] = np.nan\n",
    "    df.value = np.where(df.value < 0, np.nan, df.value)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-furniture",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-relationship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_increment_mode(df):\n",
    "\n",
    "    time_diff = (df.index[1:] - df.index[:-1]).values\n",
    "    mode = stats.mode(time_diff).mode[0]\n",
    "    time_increment_mode = mode / np.timedelta64(1, \"s\")\n",
    "    return time_increment_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-store",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dashboard_cell(DA, QCI):\n",
    "\n",
    "    metrics = pd.DataFrame(data=np.array([DA, QCI]), columns=[\"\"], index=[\"DA\", \"QCI\"])\n",
    "\n",
    "    # Apply color and formatting to metrics table\n",
    "    style_table = (\n",
    "        metrics.style.format(\"{:.2f}\")\n",
    "        .applymap(color_value)\n",
    "        .highlight_null(null_color=\"gray\")\n",
    "        .render()\n",
    "    )\n",
    "\n",
    "    # Store content to be displayed in the dashboard\n",
    "    content = {\"table\": style_table}\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-matter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Imported_OpenAQ_DatasetOutlier(OpenAQ_QC_Dataset):\n",
    "    \n",
    "   Delta = \"Check for stagnant data and/or abrupt changes in the data using the difference between max and min values (delta) within a rolling window\"\n",
    "      \n",
    "   UpperBound = \"Check for data that is outside expected range and Upper Bound\"\n",
    "   \n",
    "   LowerBound = \"Check for data that is outside expected range for Lower Bound\"\n",
    "   \n",
    "   Increment = \"Check data increments using the difference between values\"\n",
    "\n",
    "   Timestamp = \"Check time series for missing, non-monotonic and duplicate timestamps\"\n",
    "   \n",
    "   Outlier = \"Check for outliers using normalized data within a rolling window The upper and lower bounds are specified in standard deviations. Data normalized using (data-mean)/std.\"\n",
    "   \n",
    "   FunctionModel = \"Analyse\"\n",
    "   \n",
    "   NotComplete = \"Check for missing data\"\n",
    "    \n",
    "   QCI = \"QCI \"\n",
    " \n",
    "   if(OpenAQ_QC_Dataset == 0):\n",
    "\n",
    "       print(\"Criteria 1 Time Stamp\")\n",
    "       \n",
    "       print(Timestamp)\n",
    "\n",
    "       print(\"Criteria 2 Upper Lower Bound\")\n",
    "\n",
    "       print(UpperBound)\n",
    "       \n",
    "       print(LowerBound)\n",
    "       \n",
    "       print(\"Criteria 3 Delta \")\n",
    "\n",
    "       print(Delta)\n",
    "       \n",
    "       print(\"Criteria 4 Increment\")\n",
    "\n",
    "       print(Increment)\n",
    "       \n",
    "       print(\"Criteria 5 Outlier\")\n",
    "\n",
    "       print(Outlier)\n",
    "       \n",
    "       print(\"Criteria 6 Model Function\")\n",
    "\n",
    "       print(FunctionModel)\n",
    "       \n",
    "       print(\"Criteria 7 Missing Dataset\")\n",
    "\n",
    "       print(NotComplete)\n",
    "   \n",
    "       print(\"Performance Metric QCI \")\n",
    "\n",
    "       print(QCI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-villa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQDatasetSelect): \n",
    "    \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = '../Milestone1_Importing-datasets-from-OpenAQ/'\n",
    "   \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = OpenAQ_Dataset_LatlngCSV_Download + OpenAQDatasetSelect\n",
    "   \n",
    "   ImportOpenAQimported = pd.read_csv(OpenAQ_Dataset_LatlngCSV_Download) \n",
    "   \n",
    "   print(ImportOpenAQimported['parameter'])\n",
    "  \n",
    "   return ImportOpenAQimported "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-surface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-tours",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_Imported_OpenAQ_Dataset_OpenAQDataset_Test(): \n",
    "    \n",
    "   OpenAQ_Dataset_LatlngCSV_Download = '../Milestone1_Importing-datasets-from-OpenAQ/OpenAQ_Dataset1pm25Country2018-03-01to2020-09-01.csv'\n",
    "       \n",
    "   ImportOpenAQimported = pd.read_csv(OpenAQ_Dataset_LatlngCSV_Download)\n",
    "    \n",
    "   print(ImportOpenAQimported['parameter'])\n",
    " \n",
    "   return ImportOpenAQimported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-collector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-soccer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Milestone3_Get_OpenAQresults(OpenAQDFResults, OpenAQDataset, QCI):\n",
    "  \n",
    "   OpenAQappend = [] \n",
    "\n",
    "   OpenAQmetric = []\n",
    "\n",
    "   for Outlier, df in OpenAQDFResults.groupby('Error Flag'):\n",
    "\n",
    "     \n",
    "      print(Outlier)   \n",
    "    \n",
    "      print(len(df))\n",
    "    \n",
    "      OpenAQappend.append(len(df)) \n",
    "      \n",
    "      OpenAQappend.append(str(Outlier))\n",
    "     \n",
    "   OpenAQappend.append(\"QCI\")   \n",
    " \n",
    "   OpenAQappend.append(QCI.value)\n",
    "   \n",
    "   \n",
    "   OpenAQDatsetappend = pd.DataFrame(OpenAQappend)\n",
    "        \n",
    "   return OpenAQDatsetappend \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-count",
   "metadata": {},
   "source": [
    "# Step 1 Get Measurements from openAQ API \n",
    "#\n",
    "#  1 Change the OpenAQ dataset CSV to latest downloaded from Milestone 1 Using Cooridnate and Radius \n",
    "#\n",
    "#    Change OpenAQDatasetSelected to OpenAQ Dataset \n",
    "#\n",
    "#    The address is printed out after completing Milestone 1 Process\n",
    "#\n",
    "#  2 Add unique iteration \n",
    "#   \n",
    "#      edit  iteration_OpenAQStations = '0'\n",
    "#\n",
    "#\n",
    "#  3  \n",
    "#    Add in Coordinates and Radius\n",
    "#       \n",
    "#\n",
    "#  Limitations\n",
    "#\n",
    "#   It must be the OpenAQ Dataset downloaded using Coordinate and Radius \n",
    "#\n",
    "#  Test \n",
    "#\n",
    "#\n",
    "#  OpenAQDatasetSelected_Test = 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "#\n",
    "#  Milestone3_Get_Imported_OpenAQ_Dataset_Test(OpenAQDatasetSelected_Test, 1, \"Test Coordindate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenAQDataset_VisualAnalytics_Results = []\n",
    "\n",
    "# Step 1 Get Measurements from openAQ API \n",
    "#\n",
    "#  1 Change the OpenAQ dataset CSV to latest downloaded from Milestone 1 Using Cooridnate and Radius \n",
    "#\n",
    "#    Change OpenAQDatasetSelected to OpenAQ Dataset \n",
    "#\n",
    "#    The address is printed out after completing Milestone 1 Process\n",
    "#\n",
    "#  2 Add unique iteration \n",
    "#   \n",
    "#      edit  iteration_OpenAQStations = '0'\n",
    "#\n",
    "#\n",
    "#  3  \n",
    "#    Add in Coordinates and Radius\n",
    "#       \n",
    "#\n",
    "#  Limitations\n",
    "#\n",
    "#   It must be the OpenAQ Dataset downloaded using Coordinate and Radius \n",
    "#\n",
    "#  Test \n",
    "#\n",
    "#\n",
    "#  OpenAQDatasetSelected_Test = 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "#\n",
    "#  Milestone3_Get_Imported_OpenAQ_Dataset_Test(OpenAQDatasetSelected_Test, 1, \"Test Coordindate\")\n",
    "\n",
    "print(\"  STEP 1 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Getting Measurements from OpenAQ API source imported in Milestone 1 from Coordinate and Radius\")\n",
    "\n",
    "#### Edit \n",
    "\n",
    "OpenAQDatasetSelected = \"OpenAQ_Dataset Unique  debugged radius 10500 CoordinateCentreandRadius 2020-03-01 to 2020-03-04.csv\" # \"OpenAQ_Dataset unique debugged['BE', 'AE'] pm25 Country 2020-03-01 to 2020-03-04.csv\" # 'OpenAQ_Dataset unique debugBE pm25 Country 2020-03-01 to 2020-03-04.csv' # 'OpenAQ_Dataset Unique selection pm25 One Station 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "\n",
    "# 'OpenAQ_Dataset Unique selection 24.4244 54.43375 pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "\n",
    "# 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv' # 'OpenAQ_Dataset AT4S406 pm25.csv' # 'OpenAQ_Dataset Unique selection pm25 CoordinateCentreandRadius 2020-03-01 to 2020-09-01.csv'\n",
    "\n",
    "ImportedOpenAQimport = Milestone3_Get_Imported_OpenAQ_Dataset(OpenAQDatasetSelected)\n",
    "\n",
    "\n",
    "print(ImportedOpenAQimport)\n",
    "\n",
    "print(\"Choosen Unique Iteration \")\n",
    "\n",
    "iteration_OpenAQStations = '1'  #Edit \n",
    "\n",
    "print(iteration_OpenAQStations)\n",
    "\n",
    "print(\"Chosen OpenAQ Coordinates and Radius: \")\n",
    "     \n",
    "OpenAQStationCountry = \"default 24.4244,54.43375\" #Edit\n",
    "\n",
    "Radius = 25000 # Edit in metres \n",
    "\n",
    "print(\"Completed Step 1 \")\n",
    "\n",
    "print(\">\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 OpenAQ AQ Observations variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  STEP 2 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"OpenAQ Dataset imported \")\n",
    "\n",
    "print(OpenAQDatasetSelected)\n",
    "\n",
    "print(ImportedOpenAQimport.dtypes)\n",
    "\n",
    "\n",
    "print(\"Completed Step 2 \")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-custom",
   "metadata": {},
   "source": [
    "# Step 3 Found these AQ Stations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  STEP 3 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "\n",
    "print(\"Found these Stations from Coordinates\")\n",
    "\n",
    "OpenAQStationunique = ImportedOpenAQimport['location'].unique()\n",
    "\n",
    "print(OpenAQStationunique)\n",
    "\n",
    "\n",
    "print(\"Completed Step 3 \")\n",
    "\n",
    "print(\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indonesian-revelation",
   "metadata": {},
   "source": [
    "# Step 4 Find the parameter of OpenAQ Dataset\n",
    "#\n",
    "#  1 Edit to default parameter if not in OpenAQ dataset\n",
    "#\n",
    "# Test \n",
    "#\n",
    "#  1 That is only one parameter \n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"  STEP 4 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "# Step 4 Find the parameter of OpenAQ Dataset\n",
    "#\n",
    "#  1 Edit to default parameter if not in OpenAQ dataset\n",
    "#\n",
    "# Test \n",
    "#\n",
    "#  1 That is only one parameter \n",
    "# \n",
    "#\n",
    "print(\"Parameter\")\n",
    "\n",
    "Parameter_Default = 'pm25' # Edit\n",
    "\n",
    "OnlyOneParameter = 0 # Edit 0 - No and 1 Yes\n",
    "\n",
    "\n",
    "if(OnlyOneParameter == 1):\n",
    "    ImportedOpenAQimport = Milestone1_Get_Parameter(ImportedOpenAQimport, Parameter_Default)\n",
    "\n",
    "    parameter_selection = []\n",
    "    \n",
    "    parameter_selection.append(Parameter_Default)\n",
    "\n",
    "else:\n",
    "  \n",
    "    parameter_selection = ImportedOpenAQimport['parameter'].unique()\n",
    "\n",
    "print(\"Completed Step 4 \")\n",
    "\n",
    "print(\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-seattle",
   "metadata": {},
   "source": [
    "# Step 5 Finding time schedule \n",
    "#\n",
    "# \n",
    "# 1 Change default Time Schedule from 6 months to other in dt_begin\n",
    "#  and dt_end\n",
    "#\n",
    "#  dt_begin =  date(2020,3,1) 1 March 2020 \n",
    "#\n",
    "#  dt_end =  date(2020,9,1) 1 September 2020\n",
    "#\n",
    "# Change these\n",
    "#\n",
    "# dt1begin = date(2020,3,1) # Edit\n",
    "#\n",
    "# dt1end = date(2020,9,1) # Edit\n",
    "#\n",
    "# dt_begin = dt1begin\n",
    "#\n",
    "# dt_end = dt1end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 Finding time schedule \n",
    "#\n",
    "# \n",
    "# 1 Change default Time Schedule from 6 months to other in dt_begin\n",
    "#  and dt_end\n",
    "#\n",
    "#  dt_begin =  date(2020,3,1) 1 March 2020 \n",
    "#\n",
    "#  dt_end =  date(2020,9,1) 1 September 2020\n",
    "#\n",
    "# Change these\n",
    "#\n",
    "# dt1begin = date(2020,3,1) # Edit\n",
    "#\n",
    "# dt1end = date(2020,9,1) # Edit\n",
    "#\n",
    "# dt_begin = dt1begin\n",
    "#\n",
    "# dt_end = dt1end\n",
    "\n",
    "print(\"  STEP 5 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "ChooseTimeScheduleNoorYes = 0 # Edit 0 No and 1 Yes  \n",
    "\n",
    "dt_begin = min(ImportedOpenAQimport['date.utc'])\n",
    "\n",
    "dt_end = max(ImportedOpenAQimport['date.utc'])\n",
    "\n",
    "\n",
    "if(ChooseTimeScheduleNoorYes == 1):\n",
    "\n",
    "  dt_begin = date(2020,3,1)\n",
    "    \n",
    "  dt_end = date(2020,9,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "print(dt_begin)\n",
    "print(\" to \")\n",
    "print(dt_end)\n",
    "print(\" for one OpenAQ Stations and one parameter \")\n",
    "\n",
    "\n",
    "print(\"Completed Step 5 \")\n",
    "\n",
    "print(\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-graduate",
   "metadata": {},
   "source": [
    "# Step 6 Choose to remove measurement that have -999.00\n",
    "#\n",
    "# 1 It only removes -999.0 that are missing measurements \n",
    "#\n",
    "#  Edit the Remove_Neg to either\n",
    "#\n",
    "#   1 - Remove -999.0 from dataset \n",
    "# \n",
    "#   0 - Don't remove -999.0 from dataset\n",
    "#\n",
    "#  i.e Change to chosen\n",
    "# \n",
    "#   Remove_Neg = 1\n",
    "#\n",
    "#  2 Choose to remove negative measurements \n",
    "#\n",
    "#  Change  Remove_Negative_Measurements\n",
    "#  \n",
    "#   1 - Remove negative measurements \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 Choose to remove measurement that have -999.00\n",
    "#\n",
    "# 1 It only removes -999.0 that are missing measurements \n",
    "#\n",
    "#  Edit the Remove_Neg to either\n",
    "#\n",
    "#   1 - Remove -999.0 from dataset \n",
    "# \n",
    "#   0 - Don't remove -999.0 from dataset\n",
    "#\n",
    "#  i.e Change to chosen\n",
    "# \n",
    "#   Remove_Neg = 1\n",
    "#\n",
    "#  2 Choose to remove negative measurements \n",
    "#\n",
    "#  Change  Remove_Negative_Measurements\n",
    "#  \n",
    "#   1 - Remove negative measurements \n",
    "\n",
    "\n",
    "print(\"  STEP 6 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Choose to remove missing measurements that are -999.0 and below 0\")\n",
    "\n",
    "Remove_Neg = 1 # Edit      Removes Only measurements of -999.0 \n",
    "\n",
    "Remove_Negative_Measurements = 1 # Edit Remove measure below 0 \n",
    "\n",
    "Remove_Neg_NO = 0\n",
    "\n",
    "Remove_Neg_YES = 1\n",
    "\n",
    "if(Remove_Neg == Remove_Neg_YES):\n",
    "  ImportedOpenAQimport = Milestone2_Remove_neg_attribute(ImportedOpenAQimport)\n",
    "  print(\"Removing missing measurements that are -999.0\")\n",
    "else:\n",
    "  print(\"Not removing missing measurements that are -999.0\")  \n",
    "  \n",
    "if(Remove_Negative_Measurements == Remove_Neg_YES):\n",
    "  ImportedOpenAQimport = Milestone2_Remove_negative_attribute(ImportedOpenAQimport)\n",
    "  print(\"Removing measurement below 0\")\n",
    "  \n",
    "  \n",
    "\n",
    "print(\"Completed Step 6 \")\n",
    "\n",
    "print(\">\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subtle-rough",
   "metadata": {},
   "source": [
    "# Step 7 Do Data Wrangling on OpenAQ dataset  \n",
    "#\n",
    "# 1 It convert utc to DateTime for Pecos Quality Control and utc to index\n",
    "#\n",
    "#  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-richards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-rochester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-journey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7 Do Data Wrangling on OpenAQ dataset  \n",
    "#\n",
    "# 1 It convert utc to DateTime for Pecos Quality Control and utc to index\n",
    "#\n",
    "#   \n",
    "  \n",
    "\n",
    "print(\"  STEP 7 \")\n",
    "\n",
    "print(\"********\")\n",
    "  \n",
    "print(\"Data Wrangling OpenAQ dataset evaluating UTC date to Date format and setting utc to index\")\n",
    "\n",
    "ImportedOpenAQimport = Milestone2_Get_OpenAQ_Dataset_Wrangling_utc_index(ImportedOpenAQimport)\n",
    "  \n",
    "\n",
    "print(\"Dataset Wrangling Completed\")\n",
    "\n",
    "print(\"OpenAQ Dataset imported \")\n",
    "\n",
    "print(ImportedOpenAQimport.dtypes)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Completed Step 7 \")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-proxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 Import just Measurements to Dataframe with Date utc index for applying "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 Import just Measurements to Dataframe with Date utc index for applying \n",
    "\n",
    "print(\"  STEP 8 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Get measurement to Dataframe\")\n",
    "\n",
    "OpenAQAPIdataset = pd.DataFrame(ImportedOpenAQimport, columns=['value','location','unit','parameter'])\n",
    "\n",
    "print(\"Completed Step 8 \")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-possibility",
   "metadata": {},
   "source": [
    "# Step 9 Plot OpenAQ Dataset to Line plot and Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 9 Plot OpenAQ Dataset to Line plot and Histogram\n",
    "\n",
    "print(\"  STEP 9 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Graph of OpenAQ Dataset Measumrents\")\n",
    "\n",
    "OpenAQ_unit = str(ImportedOpenAQimport['unit'][0]) \n",
    "\n",
    "OpenAQDataset_VisualAnalytics = \"OpenAQ Dataset QC\" + \" \" + \" Time Schedule \" + str(dt_begin) + \" to \" + str(dt_end)\n",
    "\n",
    "OpenAQDataset_VisualAnalytics_iteration = \"OpenAQDataset QC \" + \" \"  + \" iteration \" + iteration_OpenAQStations\n",
    "\n",
    "OpenAQDataset = Milestone2_OpenAQ_Dataset_VisualAnalytics_Histogram_Unique(OpenAQAPIdataset, OpenAQStationunique, OpenAQDataset_VisualAnalytics, OpenAQDataset_VisualAnalytics_iteration)\n",
    "\n",
    "# Milestone3_Get_Imported_OpenAQ_Dataset_parameter_unique_Test(ImportedOpenAQimport,OpenAQDataset, 1,\"Test unique parameter\")\n",
    "\n",
    "\n",
    "print(\"Completed Step 9 \")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-memphis",
   "metadata": {},
   "source": [
    "# Step 10 Completing the Pecos Quality Control \n",
    "#\n",
    "#  1 The Search Criteria are edited in the Method \n",
    "#\n",
    "#  Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation\n",
    "#\n",
    "#  2 To incude completeness test to 1\n",
    "#\n",
    "#  Edit  QC_CheckDatasetComplete\n",
    "#\n",
    "#  3 To use YAML for Search Criteria \n",
    "#\n",
    "#  Change yaml_Yes to 1  \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10 Completing the Pecos Quality Control \n",
    "#\n",
    "#  1 The Search Criteria are edited in the Method \n",
    "#\n",
    "#  Milestone3_Pecos_Complete_QualityControl_One_OpenAQStation\n",
    "#\n",
    "#  2 To incude completeness test to 1\n",
    "#\n",
    "#  Edit  QC_CheckDatasetComplete\n",
    "#\n",
    "#  3 To use YAML for Search Criteria \n",
    "#\n",
    "#  Change yaml_Yes to 1  \n",
    "#\n",
    "\n",
    "\n",
    "print(\"  STEP 10 \")\n",
    "\n",
    "print(\"********\")\n",
    "\n",
    "print(\"Get Pecos Quality Control on OpenAQ dataset\")\n",
    "\n",
    "yaml_Yes = 1\n",
    "\n",
    "\n",
    "DASHBOARDPATH = f\"openaq_dashboard.html\"\n",
    "\n",
    "\n",
    "QC_CheckDatasetComplete = 0 # To incude completeness test - 0 - To include  1 - To not include  \n",
    "\n",
    "print(\"OpenAQ Pecos Quality Control Search Criteria: \")\n",
    "\n",
    "\n",
    "\n",
    "Milestone3_Pecos_Complete_QC_QualityControl_OpenAQStation(ImportedOpenAQimport, OpenAQDataset_VisualAnalytics_iteration, OpenAQStationunique, OpenAQDataset, yaml_Yes)\n",
    "\n",
    "create_pecos_dashboard(parameter_selection, OpenAQStationunique, DASHBOARDPATH)\n",
    "\n",
    "\n",
    "\n",
    "print(\" **** \")\n",
    "\n",
    "OpenAQ_QC_Dataset = 0\n",
    "\n",
    "Milestone3_Get_Imported_OpenAQ_DatasetOutlier(OpenAQ_QC_Dataset)\n",
    "\n",
    "print(\" Results in Monitoring report\")\n",
    "\n",
    "for OpenAQDataset in OpenAQDataset_VisualAnalytics_Results:\n",
    "    \n",
    "   print(OpenAQDataset)\n",
    "\n",
    "print(\"Completed Step 10\")\n",
    "\n",
    "print(\">\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-summary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-order",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-assignment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-highway",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-reggae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-absence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-practice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-converter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-personal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
